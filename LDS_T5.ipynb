{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZ+ByOx6VnuTn6c8TEx3UL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "af179055c03a444da6a97cf992f852dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fec5cb5c1a142d8ad88d81ed4cf6bce",
              "IPY_MODEL_af374ab375064a4da1f75cde0472af0b",
              "IPY_MODEL_ba465f80d95e447693fd1e46a13b5703"
            ],
            "layout": "IPY_MODEL_c0493f87c706451b993ee30e8ca11b18"
          }
        },
        "2fec5cb5c1a142d8ad88d81ed4cf6bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f9ff87077164ddbbfd4c35e7352a139",
            "placeholder": "​",
            "style": "IPY_MODEL_cf824dfd23684af2a04e18fa4681bb03",
            "value": "100%"
          }
        },
        "af374ab375064a4da1f75cde0472af0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04cb6719b0924e5d898db9fd7847570b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e1f2d1ac17e4085840ffc440b4242eb",
            "value": 1
          }
        },
        "ba465f80d95e447693fd1e46a13b5703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0951e44850f44a9f8b1e752e01827721",
            "placeholder": "​",
            "style": "IPY_MODEL_eef0b347a3ab438488edad783e0fdfcf",
            "value": " 1/1 [00:00&lt;00:00,  1.63ba/s]"
          }
        },
        "c0493f87c706451b993ee30e8ca11b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9ff87077164ddbbfd4c35e7352a139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf824dfd23684af2a04e18fa4681bb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04cb6719b0924e5d898db9fd7847570b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e1f2d1ac17e4085840ffc440b4242eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0951e44850f44a9f8b1e752e01827721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef0b347a3ab438488edad783e0fdfcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a9fcdd8ad5e436ba6efe0a251536337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e0ccd607799477a8eda4e82e32df27c",
              "IPY_MODEL_0e2327ef0e934cc0b6d4f6a29c3f508c",
              "IPY_MODEL_1976a348014647cbbee66dbbb42b88cf"
            ],
            "layout": "IPY_MODEL_d20e816f9a8e4f8ebe4def4c750e38ed"
          }
        },
        "8e0ccd607799477a8eda4e82e32df27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027ead5d9d8b4f2387e027c97fa7424a",
            "placeholder": "​",
            "style": "IPY_MODEL_1e3ac1b8551e4e83beb3e2ddfd8b5d84",
            "value": "100%"
          }
        },
        "0e2327ef0e934cc0b6d4f6a29c3f508c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e266eb06b92415aabaf91bd5c7e3bdc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27fd834fdbf54998abe56a025e15d1d3",
            "value": 1
          }
        },
        "1976a348014647cbbee66dbbb42b88cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_319fd744f2954fdc88ffd98312a9ed82",
            "placeholder": "​",
            "style": "IPY_MODEL_a487ae2be8934b99ac207b1309be1360",
            "value": " 1/1 [00:00&lt;00:00, 15.08ba/s]"
          }
        },
        "d20e816f9a8e4f8ebe4def4c750e38ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "027ead5d9d8b4f2387e027c97fa7424a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3ac1b8551e4e83beb3e2ddfd8b5d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e266eb06b92415aabaf91bd5c7e3bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27fd834fdbf54998abe56a025e15d1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "319fd744f2954fdc88ffd98312a9ed82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a487ae2be8934b99ac207b1309be1360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabilan942/Legal/blob/main/LDS_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WcmjGNF3Hr_",
        "outputId": "576056a0-31aa-4a46-8490-711d79dbfc1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.21.0\n",
        "!pip install sentencepiece\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM \n",
        "import nltk\n",
        "!pip install rouge\n",
        "nltk.download('punkt')\n",
        "from rouge import Rouge\n",
        "!pip install datasets\n",
        "from datasets import Dataset, DatasetDict\n",
        "!pip install rouge_score\n",
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import tokenize\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, '../')\n",
        "from IPython.display import display, HTML\n",
        "import torch\n",
        "from datasets import load_dataset, load_metric, Dataset\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "import evaluate\n",
        "rouge_score = evaluate.load('rouge')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COV-UaM9Tu8G",
        "outputId": "c5e78075-4d23-44da-fe43-b49a26049b90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.21.0 in /usr/local/lib/python3.8/dist-packages (4.21.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.0) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.0) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.0) (0.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.0) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.0) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.0) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.0) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.0) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.0) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.0) (1.26.14)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.8/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.8/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.8/dist-packages (4.21.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.12.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.19.6)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.1.97)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CLS Chunking"
      ],
      "metadata": {
        "id": "VytGlA3GoZQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = False)\n",
        "bert_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_y5OCxvokXp",
        "outputId": "bd898cac-47b7-4b74-eb74-326b788b50b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Have to change path**"
      ],
      "metadata": {
        "id": "QrqYtD97p7GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_root_path():\n",
        "    '''\n",
        "    function to get root path of dataset\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "    path = \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/Single/\"\n",
        "    return path\n",
        "\n",
        "def get_summary_data():\n",
        "    '''\n",
        "    function to get names, documents, and summaries\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "    \n",
        "    path = get_root_path() + '/judgement'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_source = []\n",
        "    names = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            p = filename.rfind(\"/\")\n",
        "            names.append(filename[p+1:])\n",
        "            a = f.read()\n",
        "            data_source.append(a)\n",
        "    path = get_root_path() + '/summary'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_summary = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f: \n",
        "            a = f.read()\n",
        "            l = len(a)\n",
        "            data_summary.append(a)\n",
        "            \n",
        "    return names, data_source, data_summary\n",
        "\n",
        "def split_to_sentences(para):\n",
        "    sents = nltk.sent_tokenize(para)   # returns list of sentences from para\n",
        "    return sents\n"
      ],
      "metadata": {
        "id": "yp77qOrDooCE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names, data_source, data_summary = get_summary_data()\n",
        "print(len(names))\n",
        "print(len(data_source))\n",
        "print(len(data_summary))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xR6ynwZooEj",
        "outputId": "70e23f85-44fe-4f18-ce9e-8c10cb6836f3"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "15\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_source[0]), len(data_summary[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtdtbCFsovuo",
        "outputId": "dd7faf44-8e2c-451d-e4b9-8ae12bef181e"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13340, 837)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_source[0].split()), len(data_summary[0].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSlNk_6Eovwp",
        "outputId": "35a74680-e21e-47ce-eca0-b362d2d878b9"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2412, 152)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sen_encoding(sents):\n",
        "    '''\n",
        "    Function to generate encoding for each word in the input list \n",
        "    input: sents - List of sentences\n",
        "    returns the list of the sentence encoding \n",
        "    '''\n",
        "    a = 0.001\n",
        "    answer = None\n",
        "    for sent in sents:\n",
        "        ip =tokenizer(sent, return_tensors='pt', max_length=150, truncation=True, padding='max_length')  # to convert input text into integer ids\n",
        "        tokens = tokenizer.convert_ids_to_tokens(ip['input_ids'][0])  # converts id into tokens with inclusion of special tokens added during tokenization such as [CLS]\n",
        "        bert_output = bert_model(**ip)  # BertModel; \n",
        "        embedding = bert_output['pooler_output'].clone().detach()\n",
        "        if answer == None:\n",
        "            answer = embedding\n",
        "            answer.resize_(1, 768)\n",
        "        else:\n",
        "            embedding.resize_(1, 768)\n",
        "            answer = torch.cat((answer, embedding),0)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "nEQ521wLov0H"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def similarity_l_l(l1, l2):\n",
        "    '''\n",
        "    Function to find the most similar sentence in the document for each sentence in the summary \n",
        "    input:  l1 - Summary sentences\n",
        "            l2 - Document sentences\n",
        "    returns a list of document sentence indexes for each sentence in the summary \n",
        "    '''\n",
        "    l = l1+l2  # list of sentences in both summary and document\n",
        "    sents_encodings = get_sen_encoding(l)   # return a list of tensors of length 768 each, for each element of the list\n",
        "    similarities=cosine_similarity(sents_encodings)   # calculates pairwise similiarities with elements in list if 2 arguments are not passed in; notice along diagonal its almost always equal to 1; https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html#sklearn.metrics.pairwise.cosine_similarity\n",
        "    \n",
        "    result = []\n",
        "    for i in range(len(l1)):\n",
        "        vals = similarities[i]\n",
        "        vals = vals[len(l1):]\n",
        "        idx = np.argmax(vals)\n",
        "        result.append(idx)\n",
        "    return result"
      ],
      "metadata": {
        "id": "SNU3wbsdooIG"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nest_sentencesV2(document,chunk_length):\n",
        "    '''\n",
        "    function to chunk a document\n",
        "    input:  document           - Input document\n",
        "            chunk_length        - chunk length\n",
        "    output: list of chunks. Each chunk is a list of sentences.\n",
        "    '''\n",
        "    nested = []\n",
        "    sent = []\n",
        "    length = 0\n",
        "    for sentence in nltk.sent_tokenize(document):\n",
        "        length += len(sentence.split(\" \"))\n",
        "        if length < chunk_length:\n",
        "            sent.append(sentence)\n",
        "        else:\n",
        "            nested.append(sent)\n",
        "            sent = []\n",
        "            sent.append(sentence)\n",
        "            length = 0\n",
        "    if len(sent)>0:\n",
        "        nested.append(sent)\n",
        "    return nested"
      ],
      "metadata": {
        "id": "CuwrEOp2o1gK"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chunks_data_from_docV2(doc, summ):\n",
        "    '''\n",
        "    Function to generate chunks along with their summaries \n",
        "    input:  doc - legal Document\n",
        "            summ - Gold standard summary\n",
        "    returns a list of chunks and their summaries \n",
        "    '''\n",
        "    chunk_summ_word_threshold = 75\n",
        "    sentence_mapping = {}\n",
        "    doc_sents = split_to_sentences(doc)\n",
        "    summ_sents = split_to_sentences(summ)\n",
        "    \n",
        "    result = (similarity_l_l(summ_sents,doc_sents))\n",
        "    \n",
        "    for i in range(len(summ_sents)):\n",
        "        sentence_mapping[doc_sents[result[i]]] = summ_sents[i]\n",
        "    \n",
        "    final_chunks = []\n",
        "    final_summ = []\n",
        "    for chunk in nest_sentencesV2(doc, 465):\n",
        "        summ = \"\"\n",
        "        for chunk_sent in chunk:\n",
        "            if chunk_sent in sentence_mapping:\n",
        "                summ = summ + sentence_mapping[chunk_sent]\n",
        "        if len(tokenizer.tokenize(summ)) >= chunk_summ_word_threshold:\n",
        "            final_chunks.append(\" \".join(chunk))\n",
        "            final_summ.append(summ)\n",
        "    return final_chunks, final_summ"
      ],
      "metadata": {
        "id": "1aF0GRINo1jv"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "training_chunks = []\n",
        "training_summs = []\n",
        "for i in tqdm(range(len(data_source))):\n",
        "    cks, summs = get_chunks_data_from_docV2(data_source[i],data_summary[i])\n",
        "    training_chunks = training_chunks + cks\n",
        "    training_summs = training_summs + summs\n",
        "#     print(i, len(training_summs), end = \", \", sep = \" : \")\n",
        "    if i%100 == 0: \n",
        "        full = list(zip(training_chunks,training_summs))\n",
        "        df = pd.DataFrame(full,columns=['data', 'summary'])\n",
        "        df.to_excel(\"FD_CLS_BK_512.xlsx\")\n",
        "#         break\n",
        "full = list(zip(training_chunks,training_summs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNrnaWIepBp0",
        "outputId": "d6e4d0f3-77dc-440a-f544-cb7f61d55fe9"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 14/15 [42:22<02:01, 121.87s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "100%|██████████| 15/15 [44:29<00:00, 177.95s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(full,columns=['data', 'summary'])\n",
        "df.to_excel(\"FD_CLS_512.xlsx\")"
      ],
      "metadata": {
        "id": "atVH6JSzpPoz"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Validation of pre-trained Model"
      ],
      "metadata": {
        "id": "f-AEwybr3YpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Have to change path**"
      ],
      "metadata": {
        "id": "j7o_p8Wr99l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '/content/FD_CLS_512.xlsx'\n",
        "df = pd.read_excel(filepath,usecols='B,C')"
      ],
      "metadata": {
        "id": "kx5AlWcl3m2_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OcKyH2yJkN0",
        "outputId": "e8aca31b-5a48-47d1-8036-6dcab009edc4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pcB5e4dl2bEV",
        "outputId": "d82cf846-8740-48c6-d637-65461cca4a12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                data  \\\n",
              "0  Sub sec tion (2) however provided that \"nothin...   \n",
              "1  72 of 1950. Petition under article 32 of the C...   \n",
              "2  The petitioner 's case is that the shareholder...   \n",
              "3  Supposing, howev er, that the impugned Act was...   \n",
              "4  The powers and the duties of the directors are...   \n",
              "\n",
              "                                             summary  \n",
              "0  The charge in respect of urban immoveable prop...  \n",
              "1  Per PATANJALI SASTRI, MUKHERJEA and DAS JJ.In ...  \n",
              "2  An incorporated company, therefore, can come u...  \n",
              "3  If on the face of the law there is no classifi...  \n",
              "4  The company was made a respondent and opposed ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-853a578f-e3b3-460c-b0eb-31941ea2244f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sub sec tion (2) however provided that \"nothin...</td>\n",
              "      <td>The charge in respect of urban immoveable prop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72 of 1950. Petition under article 32 of the C...</td>\n",
              "      <td>Per PATANJALI SASTRI, MUKHERJEA and DAS JJ.In ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The petitioner 's case is that the shareholder...</td>\n",
              "      <td>An incorporated company, therefore, can come u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Supposing, howev er, that the impugned Act was...</td>\n",
              "      <td>If on the face of the law there is no classifi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The powers and the duties of the directors are...</td>\n",
              "      <td>The company was made a respondent and opposed ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-853a578f-e3b3-460c-b0eb-31941ea2244f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-853a578f-e3b3-460c-b0eb-31941ea2244f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-853a578f-e3b3-460c-b0eb-31941ea2244f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, valid_df = train_test_split(df, test_size=0.05,shuffle=False)"
      ],
      "metadata": {
        "id": "cl1sbW1e4wvF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape,valid_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4LvtEnG481n",
        "outputId": "77aa82af-0210-4a3e-ee4b-fa04c641f056"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((51, 2), (3, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df.reset_index(inplace=True)\n",
        "valid_df.drop('index',inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "Nipula9q5S8o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "3kcgQ0WR54MV",
        "outputId": "81cea6e8-645c-4075-a2e6-9b115b8f40ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                data  \\\n",
              "0  The view taken by the High Court and which has...   \n",
              "1  If paragraph 5 itself is held to be applicable...   \n",
              "2  No reliance was placed on section 18 of the Li...   \n",
              "\n",
              "                                             summary  \n",
              "0  Judgment of the High Court of Madras reversed....  \n",
              "1  5,000 to A, the daughter of N.\" Later on, amon...  \n",
              "2  The decree holder appealed contending for the ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5698d4d1-ca98-4c82-9a59-df1253d8e11f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The view taken by the High Court and which has...</td>\n",
              "      <td>Judgment of the High Court of Madras reversed....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If paragraph 5 itself is held to be applicable...</td>\n",
              "      <td>5,000 to A, the daughter of N.\" Later on, amon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No reliance was placed on section 18 of the Li...</td>\n",
              "      <td>The decree holder appealed contending for the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5698d4d1-ca98-4c82-9a59-df1253d8e11f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5698d4d1-ca98-4c82-9a59-df1253d8e11f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5698d4d1-ca98-4c82-9a59-df1253d8e11f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dtc7eGsi1gKc"
      },
      "outputs": [],
      "source": [
        "def model_load(checkpoint):\n",
        "     #model loaded from Huggingface\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "#Model Details \n",
        "    print(\"tokenizer.model_max_length :\",tokenizer.model_max_length )# max token inputted in model 1024\n",
        "    print(\" max tokens excluding the special tokens\",tokenizer.max_len_single_sentence )# max tokens for input in model 1022\n",
        "    print(\"num_special_tokens_to_add \",tokenizer.num_special_tokens_to_add() ) # special token needed by model 2\n",
        "    return(tokenizer,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_generate(FileContent,tokenizer,model):\n",
        "    inputs = tokenizer(FileContent, return_tensors=\"pt\", max_length=1024, truncation=True) # max_length = 1024 since length exceed otherwise and goes out of index range; genrating inputs with chunks pt stands for pytorch\n",
        "    output = model.generate(inputs['input_ids'])  # inputs generated many list of tensors, from which 'input_ids' is used for generate  \n",
        "    summ_generated=tokenizer.decode(output[0], skip_special_tokens=True)# decoding the output  # output[0] used sinced tensor is find in [[]]\n",
        "    return(summ_generated)"
      ],
      "metadata": {
        "id": "DHhWB6ll6Elk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_score(summaryContent,final_summ_gen):  \n",
        "    rouge = Rouge()\n",
        "    result_rouge=rouge.get_scores(summaryContent, final_summ_gen, avg=True)\n",
        "# Printing the final list\n",
        "    return result_rouge"
      ],
      "metadata": {
        "id": "bJPhsJYJ6Eo_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "h5iojC481gKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3ec7ec-8b12-4577-aa9a-a8c51f3a2029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer.model_max_length : 512\n",
            " max tokens excluding the special tokens 511\n",
            "num_special_tokens_to_add  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer.model_max_length : 512\n",
            " max tokens excluding the special tokens 511\n",
            "num_special_tokens_to_add  1\n",
            "tokenizer.model_max_length : 512\n",
            " max tokens excluding the special tokens 511\n",
            "num_special_tokens_to_add  1\n"
          ]
        }
      ],
      "source": [
        "# inputs to the model\n",
        "if __name__ == \"__main__\":\n",
        "  checkpoint = \"t5-small\"\n",
        "  result_rouge_list = []\n",
        "  for i in range(valid_df.shape[0]):\n",
        "    FileContent,summaryContent=valid_df['data'][i], valid_df['summary'][i]\n",
        "    tokenizer,model=model_load(checkpoint)\n",
        "    final_summ_gen=sum_generate(FileContent,tokenizer,model)\n",
        "    result_rouge_list.append(rouge_score(summaryContent,final_summ_gen))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result_rouge_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBUV9vft7Bi8",
        "outputId": "2aa6cadf-5dcc-4cd1-ee40-4ad685220b86"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg_rouge_score = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-s6kDyV7GPG",
        "outputId": "b64cf519-6cbc-487d-c164-d0977d092d73"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge-1': {'r': 0.5023809523809524, 'p': 0.04105263157894737, 'f': 0.07580378809495004}, 'rouge-2': {'r': 0.23511904761904762, 'p': 0.012944856226672975, 'f': 0.024313052586233456}, 'rouge-l': {'r': 0.4547619047619048, 'p': 0.03754385964912281, 'f': 0.06926784038253174}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKREfDSi_FP1"
      },
      "source": [
        "## Fine-tuning T5 using CLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "tpxBVHS1Aoqb"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)                                  \n",
        "val_dataset = Dataset.from_pandas(valid_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg2J796l3FPo",
        "outputId": "e8df57c9-cbb2-4ba5-d0b0-3312edb54d3b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bn7WuVRKn1n",
        "outputId": "8180e08e-1fbc-4e52-bb74-ae1f082914ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "468"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "len(train_df['data'][0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "bW_DTfdZDT4J"
      },
      "outputs": [],
      "source": [
        "datasets = DatasetDict()\n",
        "datasets['train'] = train_dataset.remove_columns('__index_level_0__')\n",
        "datasets['valid'] = val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjZU_YqcD9qR",
        "outputId": "71dc1a8b-fce0-4fff-bcd1-0b492f6ce577"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['data', 'summary'],\n",
              "        num_rows: 51\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['data', 'summary'],\n",
              "        num_rows: 3\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UlayYJajNP8s"
      },
      "outputs": [],
      "source": [
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZRd-WkY7NP8s"
      },
      "outputs": [],
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 256\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  # Reviews are first tokenized\n",
        "  model_inputs = tokenizer(examples['data'], truncation=True, max_length=max_input_length)\n",
        "  # tokenizer for the target (highlights)\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(examples['summary'], truncation=True, max_length=max_target_length)\n",
        "  # The inputs are first encoded, and then the labels ('highlights') are encoded as a separate column\n",
        "  model_inputs['labels'] = labels['input_ids']\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "af179055c03a444da6a97cf992f852dd",
            "2fec5cb5c1a142d8ad88d81ed4cf6bce",
            "af374ab375064a4da1f75cde0472af0b",
            "ba465f80d95e447693fd1e46a13b5703",
            "c0493f87c706451b993ee30e8ca11b18",
            "1f9ff87077164ddbbfd4c35e7352a139",
            "cf824dfd23684af2a04e18fa4681bb03",
            "04cb6719b0924e5d898db9fd7847570b",
            "6e1f2d1ac17e4085840ffc440b4242eb",
            "0951e44850f44a9f8b1e752e01827721",
            "eef0b347a3ab438488edad783e0fdfcf",
            "9a9fcdd8ad5e436ba6efe0a251536337",
            "8e0ccd607799477a8eda4e82e32df27c",
            "0e2327ef0e934cc0b6d4f6a29c3f508c",
            "1976a348014647cbbee66dbbb42b88cf",
            "d20e816f9a8e4f8ebe4def4c750e38ed",
            "027ead5d9d8b4f2387e027c97fa7424a",
            "1e3ac1b8551e4e83beb3e2ddfd8b5d84",
            "0e266eb06b92415aabaf91bd5c7e3bdc",
            "27fd834fdbf54998abe56a025e15d1d3",
            "319fd744f2954fdc88ffd98312a9ed82",
            "a487ae2be8934b99ac207b1309be1360"
          ]
        },
        "outputId": "d6fe8314-fd93-4afc-f65e-e890bb90e490",
        "id": "ETVxkhzUNP8s"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af179055c03a444da6a97cf992f852dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a9fcdd8ad5e436ba6efe0a251536337"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_dataset = datasets.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e34c85-bbec-4ab9-d0df-06b829534c53",
        "id": "ToeEMwvXNP8t"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['data', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 51\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['data', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3XRiPuOSNP8t"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# Seq2SeqLM: sequence-to-sequence language modeling head\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")  # model_checkpoint = \"t5-small\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters of Seq2SeqTrainingArguments\n",
        "batch_size = 8\n",
        "num_training_epochs = 2\n",
        "logging_steps = len(tokenized_dataset[\"train\"])//8\n",
        "model_name = \"t5-small-finetuned-cls-part\"\n",
        "model_dir = \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-part.h5\"\n",
        "\n",
        "args = Seq2SeqTrainingArguments(evaluation_strategy='epoch',\n",
        "                                learning_rate=5.6e-5,\n",
        "                                per_device_train_batch_size=batch_size,\n",
        "                                per_device_eval_batch_size=batch_size,\n",
        "                                weight_decay=0.01,\n",
        "                                save_total_limit=3,\n",
        "                                num_train_epochs=num_training_epochs,\n",
        "                                predict_with_generate=True,\n",
        "                                logging_steps=logging_steps,\n",
        "                                output_dir=\"t5-finetuned-lds-cls-part\",\n",
        "                                push_to_hub=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7619a32-674e-4f10-c638-5da9d3c3e0f7",
        "id": "YgU5HW6hNP8t"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5SiGhdXSNP8t"
      },
      "outputs": [],
      "source": [
        "def compute_metric(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  # Decode generated summaries into text (summaries generated from the review_body)\n",
        "  # batch_decode -> Returns List[str]; The list of decoded sentences; Convert a list of lists of token ids into a list of strings by calling decode.\n",
        "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True) # skip_special_tokens - Whether or not to remove special tokens in the decoding.\n",
        "  # Replace -100 in the labels as we can't decode them\n",
        "  labels = np.where(labels!=-100, labels, tokenizer.pad_token_id)\n",
        "  # Decode reference summaries into text ('review_title')\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "  # ROUGE expects a newline after each sentence\n",
        "  # strip() method removes characters from both left and right based on the argument\n",
        "  decoded_preds = ['\\n'.join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "  decoded_labels = ['\\n'.join(sent_tokenize(pred.strip())) for pred in decoded_labels]\n",
        "  # Computing ROUGE score\n",
        "  # Stemming is used to remove plurals and word suffixes such as (ing, ion, ment)\n",
        "  result = rouge_score.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "  result = {key: value*100 for key, value in result.items()}\n",
        "  return {k: round(v,4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PAv8fzy6NP8t"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWZx6gP6HhPW",
        "outputId": "06421934-3cdf-4027-c371-681680401708"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['data', 'summary'], 2)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "datasets['train'].column_names, len(datasets['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1c0787-6bd5-47f1-af6b-2ec558deb575",
        "id": "UhbNjhd5NP8t"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input_ids', 'attention_mask', 'labels']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "tokenized_dataset = tokenized_dataset.remove_columns(datasets['train'].column_names)\n",
        "tokenized_dataset['train'].column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "NxgXPvIqNP8u"
      },
      "outputs": [],
      "source": [
        "# args = Seq2SeqTrainingArguments()\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "trainer = Seq2SeqTrainer(model, args, train_dataset=tokenized_dataset[\"train\"], eval_dataset=tokenized_dataset[\"valid\"], \n",
        "                         data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metric)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "v5M1Zm5b5fAn",
        "outputId": "61c340bc-2170-4544-876e-42116376f238"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 51\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 35\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 8/35 02:27 < 11:03, 0.04 it/s, Epoch 1/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 8/35 02:29 < 11:14, 0.04 it/s, Epoch 1/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 12:51]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         )\n\u001b[0;32m-> 1498\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2038\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2039\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     def predict(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2758\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2759\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3039\u001b[0m                 )\n\u001b[1;32m   3040\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3041\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-1a4affe3755a>\u001b[0m in \u001b[0;36mcompute_metric\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# Computing ROUGE score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# Stemming is used to remove plurals and word suffixes such as (ing, ion, ment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_stemmer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'compute'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg0sohM6F09Q"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Have to change path**"
      ],
      "metadata": {
        "id": "_wpLzrVC-SCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-part.h5\"\n",
        "trainer.save_model(model_dir)"
      ],
      "metadata": {
        "id": "B3ddCpnkCBBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Validation of fine-tuned Model"
      ],
      "metadata": {
        "id": "Q8L14z_F-zD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "SCq6s_iq-zD9"
      },
      "outputs": [],
      "source": [
        "def model_load(checkpoint):\n",
        "     #model loaded from Huggingface\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "#Model Details \n",
        "    #print(\"tokenizer.model_max_length :\",tokenizer.model_max_length )# max token inputted in model 1024\n",
        "    #print(\" max tokens excluding the special tokens\",tokenizer.max_len_single_sentence )# max tokens for input in model 1022\n",
        "    #print(\"num_special_tokens_to_add \",tokenizer.num_special_tokens_to_add() ) # special token needed by model 2\n",
        "    return(tokenizer,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_generate(FileContent,tokenizer,model):\n",
        "    inputs = tokenizer(FileContent, return_tensors=\"pt\", max_length=1024, truncation=True) # max_length = 1024 since length exceed otherwise and goes out of index range; genrating inputs with chunks pt stands for pytorch\n",
        "    output = model.generate(inputs['input_ids'])  # inputs generated many list of tensors, from which 'input_ids' is used for generate  \n",
        "    summ_generated=tokenizer.decode(output[0], skip_special_tokens=True)# decoding the output  # output[0] used sinced tensor is find in [[]]\n",
        "    return(summ_generated)"
      ],
      "metadata": {
        "id": "AwJ5NgMc-zD-"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_score(summaryContent,final_summ_gen):  \n",
        "    rouge = Rouge()\n",
        "    result_rouge=rouge.get_scores(summaryContent, final_summ_gen, avg=True)\n",
        "# Printing the final list\n",
        "    return result_rouge"
      ],
      "metadata": {
        "id": "K5HnTef0-zD_"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Have to change path**"
      ],
      "metadata": {
        "id": "U4ilW0ft-Xlp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b5bdd5-c9aa-4f16-f358-c3b3f73fec4f",
        "id": "0Pqfez-y-zD_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/spiece.model\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-size-130.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# inputs to the model\n",
        "if __name__ == \"__main__\":\n",
        "  checkpoint = \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/t5-small-finetuned-cls-part.h5\"\n",
        "  result_rouge_list = []\n",
        "  for i in range(valid_df.shape[0]):\n",
        "    FileContent,summaryContent=valid_df['data'][i], valid_df['summary'][i]\n",
        "    tokenizer,model=model_load(checkpoint)\n",
        "    final_summ_gen=sum_generate(FileContent,tokenizer,model)\n",
        "    result_rouge_list.append(rouge_score(summaryContent,final_summ_gen))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result_rouge_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d21b0f-bdb7-4a15-cb91-678f07344db8",
        "id": "Mm9m3zEO-zEA"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg_rouge_score = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca6f410-8b53-40eb-b8cf-ad105f947e7a",
        "id": "ifOFd2Mv-zEB"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge-1': {'r': 0.33020202020202016, 'p': 0.04780316310364701, 'f': 0.0820922766921572}, 'rouge-2': {'r': 0.08127058127058126, 'p': 0.007673922410429862, 'f': 0.01379944906931314}, 'rouge-l': {'r': 0.31858585858585853, 'p': 0.04555700642501312, 'f': 0.07834985831559248}}\n"
          ]
        }
      ]
    }
  ]
}