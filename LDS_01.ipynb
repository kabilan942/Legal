{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabilan942/Legal/blob/main/LDS_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OhDKu4N65Nbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fdba55-192c-40ca-b8bd-47f73980a6de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4cy0L5bl-CEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451a0566-fa56-417d-aa39-5b67fc3a4c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM \n",
        "import nltk\n",
        "!pip install rouge\n",
        "nltk.download('punkt')\n",
        "from rouge import Rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1TdG8dXJ8HIR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "documentPath = f'/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/judgement/'\n",
        "dir = os.listdir(documentPath)\n",
        "\n",
        "dir_list = []\n",
        "for i in range(len(dir)):\n",
        "  dir_list.append(int(dir[i][:-4]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCrk_kQf1_SO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def read_input():\n",
        "    file = open(\"D:/Phd_work/Dataset/Legal dataset/dataset/IN-Abs/train-data/judgement/6.txt\", \"r\")\n",
        "    FileContent = file.read().strip() # Stripping the white spaces in the file\n",
        "    file = open(\"D:/Phd_work/Dataset/Legal dataset/dataset/IN-Abs/train-data/summary/6.txt\", \"r\")\n",
        "    summaryContent = file.read().strip()\n",
        "    return(FileContent,summaryContent)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5ZmG8hE8lbf"
      },
      "source": [
        "# BART - Chunking (Single Document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU44dgxX2gIe"
      },
      "outputs": [],
      "source": [
        "def read_input():\n",
        "  doc_name = '/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/judgement/78.txt'\n",
        "  doc = open(doc_name,'r')\n",
        "  FileContent = doc.read().strip()\n",
        "  sum_name ='/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/summary/78.txt'\n",
        "  sum = open(sum_name,'r')\n",
        "  summaryContent = sum.read().strip()\n",
        "  return(FileContent,summaryContent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eizX57l1_SW",
        "outputId": "d363a8a0-39f9-40ce-94b9-dd3cd0e9d09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m125.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ],
      "source": [
        "def model_load():\n",
        "    checkpoint = \"sshleifer/distilbart-cnn-12-6\" #model loaded from Huggingface\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "#Model Details \n",
        "    print(\"tokenizer.model_max_length :\",tokenizer.model_max_length )# max token inputted in model 1024\n",
        "    print(\" max tokens excluding the special tokens\",tokenizer.max_len_single_sentence )# max tokens for input in model 1022\n",
        "    print(\"num_special_tokens_to_add \",tokenizer.num_special_tokens_to_add() ) # special token needed by model 2\n",
        "    return(tokenizer,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skesMw5K1_SY"
      },
      "outputs": [],
      "source": [
        "def chunking(FileContent,tokenizer):\n",
        "    # extract the sentences from the document\n",
        "    sentences = nltk.tokenize.sent_tokenize(FileContent) #split the data(paragraph) into individual sentences\n",
        "    print(len(sentences)) #print total no of sentences\n",
        "    # find the max tokens in the longest sentence\n",
        "    maxtokencount=max([len(tokenizer.tokenize(sentence)) for sentence in sentences])\n",
        "    print(\"maximum tokens in longest sentence:\",maxtokencount)\n",
        "\n",
        "    # initialize\n",
        "    length = 0\n",
        "    chunk = \"\"\n",
        "    chunks = []\n",
        "    count = -1\n",
        "    for sentence in sentences:\n",
        "        count += 1\n",
        "        combined_length = len(tokenizer.tokenize(sentence)) + length # add the no. of sentence tokens to the length counter\n",
        "        #print(combined_length)  #combined length of all the tokens in all sentences \n",
        "\n",
        "        if combined_length  <= tokenizer.max_len_single_sentence: # if it doesn't exceed than max_len(1022)\n",
        "            chunk += sentence + \" \" # add the sentence to the chunk with white space\n",
        "            length = combined_length # update the length counter\n",
        "\n",
        "            # if it is the last sentence\n",
        "            if count == len(sentences) - 1:\n",
        "                chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        else:   # if max token limit reaches then save the chunk\n",
        "            chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        # reset the parameter to add next tokens to next chunk\n",
        "            length = 0 \n",
        "            chunk = \"\"\n",
        "\n",
        "        # take care of the overflow sentence\n",
        "            chunk += sentence + \" \"\n",
        "            length = len(tokenizer.tokenize(sentence))\n",
        "\n",
        "            \n",
        "    print(\"Total no of chunks created\",len(chunks))\n",
        "    print(\"Total no of tokens generated by chunks\",sum([len(tokenizer(c).input_ids) for c in chunks]))\n",
        "    print(\"Total no of token in original text\",len(tokenizer(FileContent).input_ids))\n",
        "    print(\"No of tokens in each  chunk excluding the special token\",[len(tokenizer.tokenize(c)) for c in chunks])\n",
        "    return (chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq0prlX41_Sa"
      },
      "outputs": [],
      "source": [
        "def sum_generate(chunks,tokenizer,model):\n",
        "    final_summ_gen=\"\"\n",
        "    inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks] #genrating inputs with chunks pt stands for pytorch\n",
        "    for input in inputs:\n",
        "        output = model.generate(**input)    #output generated for each chunk\n",
        "        summ_generated=tokenizer.decode(*output, skip_special_tokens=True)# decoding the output\n",
        "        final_summ_gen= final_summ_gen+summ_generated\n",
        "    print(final_summ_gen)\n",
        "    return(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTaV1uNc1_Sb",
        "outputId": "c6103a1b-02c0-4f16-82d0-71dba868acc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.8/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "def rouge_score(summaryContent,final_summ_gen):  \n",
        "    rouge = Rouge()\n",
        "    result_rouge=rouge.get_scores(summaryContent, final_summ_gen, avg=True)\n",
        "# Printing the final list\n",
        "    print(result_rouge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH4V_dFI1_Sc",
        "outputId": "5086185c-6a36-44d6-bf43-2aa59686b5f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2634 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer.model_max_length : 1024\n",
            " max tokens excluding the special tokens 1022\n",
            "num_special_tokens_to_add  2\n",
            "98\n",
            "maximum tokens in longest sentence: 137\n",
            "Total no of chunks created 3\n",
            "Total no of tokens generated by chunks 2572\n",
            "Total no of token in original text 2634\n",
            "No of tokens in each  chunk excluding the special token [999, 1019, 548]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 142 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Appeal from an Order of the High Court of Bombay (Bavdekar and Chainani JJ.) dated 20th February, 1950, in Criminal Appeal No. 106 of 1950. W.H. King was tenant of a flat on the second floor of a building called \"Ganga Vihar\", Marine Drive, Bombay, which belongs to a lady named Durgeshwari Devi. The wife of the appellant denied any aiding and abetting. The wife was acquitted, the evidence being insufficient to prove any abetment. The appellant preferred an appeal to the High Court of Bombay but it was summarily dismissed. He asked for a certificate under article 134(1)(c) of the Constitution but this was rejected on 10 4 1950. He applied for special leave to appeal to this Court and it was granted on 3 10 1950. The word \"relinquishment\" does not occur in the Transfer of Property Act but it is found in many of the Tenancy Acts in various provinces where there are Sec tions which deal with the relinquishment of their holdings by tenants in favour of the landlord by notice given to him in writing. The conviction under sub clause (2) cannot be sustained, the conviction is set aside and the fine of Rs. 30,000 will be refunded if it has been paid.\n",
            "{'rouge-1': {'r': 0.291044776119403, 'p': 0.20855614973262032, 'f': 0.24299064934191253}, 'rouge-2': {'r': 0.08673469387755102, 'p': 0.049132947976878616, 'f': 0.06273062268923388}, 'rouge-l': {'r': 0.26119402985074625, 'p': 0.18716577540106952, 'f': 0.21806853096185025}}\n"
          ]
        }
      ],
      "source": [
        "# inputs to the model\n",
        "if __name__ == \"__main__\":\n",
        "  FileContent,summaryContent=read_input()\n",
        "  tokenizer,model=model_load()\n",
        "  chunks=chunking(FileContent,tokenizer)\n",
        "  final_summ_gen=sum_generate(chunks,tokenizer,model)\n",
        "  result_rouge=rouge_score(summaryContent,final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwjgZiLn1_Se",
        "outputId": "4c95df09-8217-4556-e316-bda8538cdae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Appeal from an Order of the High Court of Bombay (Bavdekar and Chainani JJ.) dated 20th February, 1950, in Criminal Appeal No. 106 of 1950. W.H. King was tenant of a flat on the second floor of a building called \"Ganga Vihar\", Marine Drive, Bombay, which belongs to a lady named Durgeshwari Devi. The wife of the appellant denied any aiding and abetting. The wife was acquitted, the evidence being insufficient to prove any abetment. The appellant preferred an appeal to the High Court of Bombay but it was summarily dismissed. He asked for a certificate under article 134(1)(c) of the Constitution but this was rejected on 10 4 1950. He applied for special leave to appeal to this Court and it was granted on 3 10 1950. The word \"relinquishment\" does not occur in the Transfer of Property Act but it is found in many of the Tenancy Acts in various provinces where there are Sec tions which deal with the relinquishment of their holdings by tenants in favour of the landlord by notice given to him in writing. The conviction under sub clause (2) cannot be sustained, the conviction is set aside and the fine of Rs. 30,000 will be refunded if it has been paid.\n"
          ]
        }
      ],
      "source": [
        "print(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qx-dm1A1_Se",
        "outputId": "32c25221-1f30-4fce-82a9-f6ff8c8961a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given Summary: Sub section (1) of sec.\n",
            "19 of the Bombay Rents, Hotel and Lodging House Rates Control Act, LVI I of 1947, provided that \"it shall not be lawful for the tenant or any person acting or purporting to act on behalf of the tenant to claim or receive any sum or any consideration as a condition for the relinquishment of his tenancy of any premises\"; and sub sec.\n",
            "(2) provided that any tenant or person who in contravention of the provisions of sub sec.\n",
            "(1) receives any sum or consideration shall on conviction be punished with imprisonment and also with fine.\n",
            "A. who was a tenant of a flat, handed over vacant posses sion the flat to B on receiving \"pugree\", under a document which recited that A shall have no claim whatever over the flat and that B shall pay the rent directly to the landlord.\n",
            "A was convicted of an offence under sec.\n",
            "19 (2).\n",
            "Held, that there was no \"relinquishment\" of his tenancy by A, within the meaning of sec.\n",
            "19 (1) and the conviction could not be sustained.\n",
            "There is a clear distinction between an assignment of a tenancy on the one hand and a relinquishment or surrender on the other.\n",
            "In the case of an assignment, the assignor con tinues to be liable to the landlord for the performance of his obligations under the tenancy and this liability is contractual, while the assignee becomes liable by reason of privity of estate.\n",
            "The consent of the landlord to an as signment is not necessary, in the absence of a contract or local usage to the contrary.\n",
            "But in the case of relinquish ment it cannot be a unilateral transaction; it can only be in favour of the lessor by mutual agreement between them.\n",
            "Relinquishment of possession must be to the lessor or one who holds his interest; and surrender or relinquishment terminates the lessee 's rights and lets in the lessor.\n",
            "As sec.\n",
            "19 of Bombay Act LVII of 1947 creates an offence and imposes a penalty of fine and imprisonment, the words of the section must be strictly construed in favour of the subject.\n",
            "The Court is not concerned so much with what might possibly have been intended as with what has been actually said in and by the language employed in the statute.\n",
            "Judgment of the Bombay High Court reversed.\n"
          ]
        }
      ],
      "source": [
        "print(\"Given Summary:\",summaryContent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiMmWKZE9Mdl"
      },
      "source": [
        "tokenizer.model_max_length : 1024\n",
        "\n",
        "max tokens excluding the special tokens 1022\n",
        "\n",
        "num_special_tokens_to_add  2  98\n",
        "\n",
        "maximum tokens in longest sentence: 137\n",
        "\n",
        "Total no of chunks created 3\n",
        "\n",
        "Total no of tokens generated by chunks 2572\n",
        "\n",
        "Total no of token in original text 2634\n",
        "\n",
        "No of tokens in each  chunk excluding the special token [999, 1019, 548]\n",
        "\n",
        "\n",
        "\n",
        "{'rouge-1': {'r': 0.291044776119403, 'p': 0.20855614973262032, 'f': 0.24299064934191253}, \n",
        "\n",
        "'rouge-2': {'r': 0.08673469387755102, 'p': 0.049132947976878616, 'f': 0.06273062268923388}, \n",
        "\n",
        "'rouge-l': {'r': 0.26119402985074625, 'p': 0.18716577540106952, 'f': 0.21806853096185025}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaU1ICk291LL"
      },
      "source": [
        "# BART - Chunking (Multiple Documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vzfipz9M91LN"
      },
      "outputs": [],
      "source": [
        "def read_input(i):\n",
        "  doc_name = f'/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/judgement/{i}.txt'\n",
        "  doc = open(doc_name,'r')\n",
        "  FileContent = doc.read().strip()\n",
        "  sum_name =f'/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/summary/{i}.txt'\n",
        "  sum = open(sum_name,'r')\n",
        "  summaryContent = sum.read().strip()\n",
        "  return(FileContent,summaryContent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5LD-e1-X91LO"
      },
      "outputs": [],
      "source": [
        "def model_load():\n",
        "    checkpoint = \"sshleifer/distilbart-cnn-12-6\" #model loaded from Huggingface\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "#Model Details \n",
        "    #print(\"tokenizer.model_max_length :\",tokenizer.model_max_length )# max token inputted in model 1024\n",
        "    #print(\" max tokens excluding the special tokens\",tokenizer.max_len_single_sentence )# max tokens for input in model 1022\n",
        "    #print(\"num_special_tokens_to_add \",tokenizer.num_special_tokens_to_add() ) # special token needed by model 2\n",
        "    return(tokenizer,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0zcJVGhP91LS"
      },
      "outputs": [],
      "source": [
        "def chunking(FileContent,tokenizer):\n",
        "    # extract the sentences from the document\n",
        "    sentences = nltk.tokenize.sent_tokenize(FileContent) #split the data(paragraph) into individual sentences\n",
        "    #print(len(sentences)) #print total no of sentences\n",
        "    # find the max tokens in the longest sentence\n",
        "    maxtokencount=max([len(tokenizer.tokenize(sentence)) for sentence in sentences])\n",
        "    #print(\"maximum tokens in longest sentence:\",maxtokencount)\n",
        "\n",
        "    # initialize\n",
        "    length = 0\n",
        "    chunk = \"\"\n",
        "    chunks = []\n",
        "    count = -1\n",
        "    for sentence in sentences:\n",
        "        count += 1\n",
        "        combined_length = len(tokenizer.tokenize(sentence)) + length # add the no. of sentence tokens to the length counter\n",
        "        #print(combined_length)  #combined length of all the tokens in all sentences \n",
        "\n",
        "        if combined_length  <= tokenizer.max_len_single_sentence: # if it doesn't exceed than max_len(1022)\n",
        "            chunk += sentence + \" \" # add the sentence to the chunk with white space\n",
        "            length = combined_length # update the length counter\n",
        "\n",
        "            # if it is the last sentence\n",
        "            if count == len(sentences) - 1:\n",
        "                chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        else:   # if max token limit reaches then save the chunk\n",
        "            chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        # reset the parameter to add next tokens to next chunk\n",
        "            length = 0 \n",
        "            chunk = \"\"\n",
        "\n",
        "        # take care of the overflow sentence\n",
        "            chunk += sentence + \" \"\n",
        "            length = len(tokenizer.tokenize(sentence))\n",
        "\n",
        "            \n",
        "    #print(\"Total no of chunks created\",len(chunks))\n",
        "    #print(\"Total no of tokens generated by chunks\",sum([len(tokenizer(c).input_ids) for c in chunks]))\n",
        "    #print(\"Total no of token in original text\",len(tokenizer(FileContent).input_ids))\n",
        "    #print(\"No of tokens in each  chunk excluding the special token\",[len(tokenizer.tokenize(c)) for c in chunks])\n",
        "    return (chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J7y0su9x91LT"
      },
      "outputs": [],
      "source": [
        "def sum_generate(chunks,tokenizer,model):\n",
        "    final_summ_gen=\"\"\n",
        "    inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks] #genrating inputs with chunks pt stands for pytorch\n",
        "    for input in inputs:\n",
        "        output = model.generate(**input)    #output generated for each chunk\n",
        "        summ_generated=tokenizer.decode(*output, skip_special_tokens=True)# decoding the output\n",
        "        final_summ_gen= final_summ_gen+summ_generated\n",
        "    #print(final_summ_gen)\n",
        "    return(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VocDj_e791LT"
      },
      "outputs": [],
      "source": [
        "def rouge_score(summaryContent,final_summ_gen):  \n",
        "    rouge = Rouge()\n",
        "    result_rouge=rouge.get_scores(summaryContent, final_summ_gen, avg=True)\n",
        "# Printing the final list\n",
        "    return result_rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Szq5gN3491LU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "c0bd2c4888334bc294380b70a6b4a189",
            "2e4b6c8a20004929a3d3dbbaf5a7c193",
            "31c801ce79c346c19571cdbfcc443a96",
            "c9976277e34a48b99e2fff7da7898291",
            "85c017b13d3a406aaf718ca281b9bc64",
            "684fd9dbc31f463d8c730e43d15c875a",
            "549bca2cdd024b91a1de2e845d0d6ce5",
            "e3412c62c7d5426a85d627c8bba02585",
            "4f2ca72b95ee4c01a0f062355ce30536",
            "81cf26079a464140ae61e542a228ea59",
            "d14bbbda1e7f42f38e371f577e0fc34e",
            "d6629a6f5b424371a24856e22994babf",
            "6df19af955894d6f87d90ddefd54fc86",
            "8fd7f0fa961f47e7b064de42c0328d7f",
            "86cd541e2e7d41f2b0ebd5672ff8bbf8",
            "1879049519a04da9b8c3634956acccd4",
            "0cb3d6700b044cd28a1fb5938abc545d",
            "8a3c1e4b0b39406f914e0548d340a20a",
            "bd552abf25d7490b837726aee009156c",
            "3db4aae5b6434b1ead1b1bb5e25beb19",
            "ca7b00db25fb41589b40892f1cd13488",
            "6a053ed0072448efbc334a7ff3b3dbba",
            "379b869ed23c494fabdc5e4e0f4e5215",
            "2b6e0addcb1448d986abb3dc6f4a57fe",
            "3b69edec7f4846a0ab7e8a130d4af7f7",
            "ff4e5e17e5a948428e92074eeb7fe45d",
            "72b8890f0557437687b67f523f8e9bbb",
            "90eaf82fb4a543a09cf484d09777d38a",
            "804cd75ce8b444a3b6e1599e7883bf9b",
            "7b5cbe48035e4de3be35d0fda07814e4",
            "b3f5466188144c4abb5632aec87b21b3",
            "4de67449b96b4d779c8fc6021fe4192f",
            "e0dc887f757545b2acd7a902dcbac3ea",
            "370b5b0478a544eca7fe41206bc50371",
            "e392593e0c304cd0b7734eed5d0bb5a9",
            "ac5d544fe2194a6099129da7dce25c6d",
            "8679eaf7e10a4267816f3b362734cea0",
            "eda4ec307d694bdd9a09e33e4fee944d",
            "75f24e49769b454c9437b4b30357121d",
            "5580d400e2384f1c86d12bd662fab7ad",
            "7c45746f5c144474b8f5694d1dc8f4f2",
            "1ab250e25b8841d8a3a8f3d98c808be9",
            "611ddba88632420d979fbec974571901",
            "37994059972d42d8bfd305f87885af19",
            "0f1c8c585679453b924ff012925c29f8",
            "eabaddf91c3749138c5957d3585c6d5c",
            "d2caad2b641e42748527d09a1ce676e6",
            "e0f6e558bd744b68bf8860b1c85339f3",
            "0857a775cde34a129a226373ee6182b8",
            "ba010b3724f5463ea4ac2fc899ca00e0",
            "ea56103285e24ba7bb96324d191bbad4",
            "b2a00ff23a484971a9b2a94272f561cb",
            "e825c535d25949b98e25f21aeb644d8a",
            "f895f67e31e44f01a42d39b97c54266f",
            "c6cce4906a43411c865d08bcf09dd5bb"
          ]
        },
        "outputId": "d4c7cec7-4c00-47dc-f2bb-c5ee1f7b0bf2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0bd2c4888334bc294380b70a6b4a189"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6629a6f5b424371a24856e22994babf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "379b869ed23c494fabdc5e4e0f4e5215"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "370b5b0478a544eca7fe41206bc50371"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f1c8c585679453b924ff012925c29f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 142 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# inputs to the model\n",
        "if __name__ == \"__main__\":\n",
        "  result_rouge_list = []\n",
        "  for i in dir_list[:30]:\n",
        "    FileContent,summaryContent=read_input(i)\n",
        "    tokenizer,model=model_load()\n",
        "    chunks=chunking(FileContent,tokenizer)\n",
        "    final_summ_gen=sum_generate(chunks,tokenizer,model)\n",
        "    result_rouge_list.append(rouge_score(summaryContent,final_summ_gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlPIiyKMpKpD",
        "outputId": "83c375d5-b725-4477-85f1-168b3e392c8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(result_rouge_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McnQ6UEymThO",
        "outputId": "b62949a6-0d1d-4c3b-faa2-e317d3e7ede6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge-1': {'r': 0.5146350977636011, 'p': 0.2939724380970604, 'f': 0.3647993139364114}, 'rouge-2': {'r': 0.293680200989159, 'p': 0.1405336410499587, 'f': 0.18339711797892372}, 'rouge-l': {'r': 0.4749069546202089, 'p': 0.26922998613889076, 'f': 0.3350146321923683}}\n"
          ]
        }
      ],
      "source": [
        "agg_rouge_score = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnQjcfx2Cv78"
      },
      "source": [
        "# BigBird - Chunking (Single Document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2DiO8ooCv8b"
      },
      "outputs": [],
      "source": [
        "def read_input():\n",
        "  doc_name = '/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/judgement/78.txt'\n",
        "  doc = open(doc_name,'r')\n",
        "  FileContent = doc.read().strip()\n",
        "  sum_name ='/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/summary/78.txt'\n",
        "  sum = open(sum_name,'r')\n",
        "  summaryContent = sum.read().strip()\n",
        "  return(FileContent,summaryContent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RA_0DxOCv8d"
      },
      "outputs": [],
      "source": [
        "from transformers import BigBirdForCausalLM\n",
        "\n",
        "def model_load():\n",
        "    checkpoint = \"google/bigbird-roberta-base\" #model loaded from Huggingface\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = BigBirdForCausalLM.from_pretrained(checkpoint,is_decoder=True)\n",
        "#Model Details \n",
        "    print(\"tokenizer.model_max_length :\",tokenizer.model_max_length )# max token inputted in model 1024\n",
        "    print(\" max tokens excluding the special tokens\",tokenizer.max_len_single_sentence )# max tokens for input in model 1022\n",
        "    print(\"num_special_tokens_to_add \",tokenizer.num_special_tokens_to_add() ) # special token needed by model 2\n",
        "    return(tokenizer,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr7XoHv9Cv8e"
      },
      "outputs": [],
      "source": [
        "def chunking(FileContent,tokenizer):\n",
        "    # extract the sentences from the document\n",
        "    sentences = nltk.tokenize.sent_tokenize(FileContent) #split the data(paragraph) into individual sentences\n",
        "    print(len(sentences)) #print total no of sentences\n",
        "    # find the max tokens in the longest sentence\n",
        "    maxtokencount=max([len(tokenizer.tokenize(sentence)) for sentence in sentences])\n",
        "    print(\"maximum tokens in longest sentence:\",maxtokencount)\n",
        "\n",
        "    # initialize\n",
        "    length = 0\n",
        "    chunk = \"\"\n",
        "    chunks = []\n",
        "    count = -1\n",
        "    for sentence in sentences:\n",
        "        count += 1\n",
        "        combined_length = len(tokenizer.tokenize(sentence)) + length # add the no. of sentence tokens to the length counter\n",
        "        #print(combined_length)  #combined length of all the tokens in all sentences \n",
        "\n",
        "        if combined_length  <= tokenizer.max_len_single_sentence: # if it doesn't exceed than max_len(1022)\n",
        "            chunk += sentence + \" \" # add the sentence to the chunk with white space\n",
        "            length = combined_length # update the length counter\n",
        "\n",
        "            # if it is the last sentence\n",
        "            if count == len(sentences) - 1:\n",
        "                chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        else:   # if max token limit reaches then save the chunk\n",
        "            chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        # reset the parameter to add next tokens to next chunk\n",
        "            length = 0 \n",
        "            chunk = \"\"\n",
        "\n",
        "        # take care of the overflow sentence\n",
        "            chunk += sentence + \" \"\n",
        "            length = len(tokenizer.tokenize(sentence))\n",
        "\n",
        "            \n",
        "    print(\"Total no of chunks created\",len(chunks))\n",
        "    print(\"Total no of tokens generated by chunks\",sum([len(tokenizer(c).input_ids) for c in chunks]))\n",
        "    print(\"Total no of token in original text\",len(tokenizer(FileContent).input_ids))\n",
        "    print(\"No of tokens in each  chunk excluding the special token\",[len(tokenizer.tokenize(c)) for c in chunks])\n",
        "    return (chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiDoG50_Cv8g"
      },
      "outputs": [],
      "source": [
        "def sum_generate(chunks,tokenizer,model):\n",
        "    final_summ_gen=\"\"\n",
        "    inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks] #genrating inputs with chunks pt stands for pytorch\n",
        "    for input in inputs:\n",
        "        output = model.generate(**input)    #output generated for each chunk\n",
        "        summ_generated=tokenizer.decode(*output, skip_special_tokens=True)# decoding the output\n",
        "        final_summ_gen= final_summ_gen+summ_generated\n",
        "    print(final_summ_gen)\n",
        "    return(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyIXWGHSCv8q"
      },
      "outputs": [],
      "source": [
        "from rouge import Rouge\n",
        "def rouge_score(summaryContent,final_summ_gen):  \n",
        "    rouge = Rouge()\n",
        "    result_rouge=rouge.get_scores(summaryContent, final_summ_gen, avg=True)\n",
        "# Printing the final list\n",
        "    print(result_rouge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wYZADwMCv8r",
        "outputId": "40d03337-3d03-4441-e842-a6a53f553b6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Input length of input_ids is 2571, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer.model_max_length : 4096\n",
            " max tokens excluding the special tokens 4094\n",
            "num_special_tokens_to_add  2\n",
            "98\n",
            "maximum tokens in longest sentence: 138\n",
            "Total no of chunks created 1\n",
            "Total no of tokens generated by chunks 2571\n",
            "Total no of token in original text 2636\n",
            "No of tokens in each  chunk excluding the special token [2569]\n",
            "N: Criminal Appeal No. 8 of 1951. Appeal from an Order of the High Court of Bombay (Bavdekar and Chainani JJ.) dated 20th February, 1950, in Criminal Appeal No. 106 of 1950 arising out of an order dated 9th January, 1950, of the Presidency Magistrate, 19th Court, Esplanade, Bombay, in Case No. 10879/P of 1949. The facts are stated in the judgment. Iswarlal C. Dalai and R.B. Dalai, for the appellant. C.K. Daphtary, Solicitor General for India (G. N. Joshi, with him) for the Republic of India (respondent No. 1).Jindra Lal for the respondent No. 2. 1952. February 1. The Judgment of the Court was deliv ered by CHANDRASEKHARA AIYAR J. The facts out of which this Crimi nal Appeal has arisen are not long. The appellant, W.H. King, who is carrying on a business in Bombay under the name and style of Associated Commercial Enterprises, was the tenant of a flat on the second floor of a building called \"Ganga Vihar\", Marine Drive, Bombay, which belongs to a lady named Durgeshwari Devi. The tenancy was a monthly one, the rent being Rs. 215. It is said that the appellant wanted to go to the United Kingdom for treatment of his failing eye sight and he got into touch with the complainant Mulchand Kodumal Bhatia, who is the second respondent in this appeal, through one Sayed for the purpose of making necessary ar rangements about the flat occupied by him in view of his intended departure. The prosecution case is that the accused demanded a sum of Rs. 30,000 which was later on reduced to Rs. 29,500 as consideration for putting the complainant in vacant possession of the flat and an additional amount of Rs. 2,000 for the furniture, and that the complainant agreed to pay these sums. The complainant actually paid the accused two sums of 420 Rs. 500 each on 7th November, 1948, and 17th November, 1948. He, however, got into touch with the police on 1 12 1948, and in conjunction with the latter, a trap was laid for the appellant. It was arranged that the complainant should bring with him Rs. 1,000, being the balance due in respect of the furniture and that the police would give him Rs. 29,500 to be paid to the appellant. The complainant and a Sub Inspec tor, posing as the complainant's brother, went to the appel lant on 4 12 1948, and paid him the two sums of money; and the keys of the flat and the motor garage were handed over to the complainant. As the appellant and his wife were leaving the flat, the man, who masqueraded as the complain ant's brother, threw off his disguise and disclosed his identity. The police party, who were down below ready for the raid, held up the car of the appellant and recovered the sum of Rs. 30,500 from the rear seat of the car and also some papers, a typed draft of a partnership agreement be tween the complainant and the appellant and an application form for permission to occupy the building as caretaker. From the complainant were recovered the bunch of keys and the documents that were handed over to him by the appellant, namely, the letter handing vacant possession (Exhibit D). the receipt for Rs. 2,000 for the articles of furniture (Exhibit E), a letter to the Bombay Gas Company for transfer of the gas connection to the name of the complainant (Exhib it F), and the letter to the Bombay Electric Supply and Transport Committee for transfer of the telephone connec tions and the deposit of Rs. 27 (Exhibit G). The appellant was charged under section 18(1) of the Bombay Rents, Hotel and Lodging House Rates Control Act, LVII of 1947, for receiving a pugree of Rs. 29,500 and he was further charged under section 19(2) of the said Act for receiving the said sum as a condition for the relin quishment of his tenancy. His wife, who was the second accused in the case, was charged with aiding and abetting her husband in the commission of the two offences. 421 The defence of the appellant was that he was in search of a partner to carry on his business during his intended absence, who was also to act as caretaker of his flat anal that it was in this connection and with this object in view that he entered into negotiations with the complain ant. The sum of Rs. 29 500 was not pugree but represented capital for 0 12 0 share in the business and as the com plainant was also to be a caretaker of the flat, the sum of Rs. 2,000 was paid and received as a guarantee against disposal and damage of the furniture and it was agreed to be paid back on the appellant's return to India. The wife of the appellant denied any aiding and abetting. The Presidency Magistrate, who tried the case, disbe lieved the defence on the facts, holding that what was received by the accused was by way of pugree. As section 18 (1) of the Act was not applicable he convicted him under section 19(2) of the Act and sentenced him, in view of his old age and blindness, to one day's simple imprisonment and a fine of Rs. 30,000. The wife was acquitted, the evidence being insufficient to prove any abetment. The appellant preferred an appeal to the High Court of Bombay but it was summarily dismissed on 20 2 1950. He asked for a certificate under article 134(1)(c) of the Constitution but this was rejected on 10 4 1950. Thereaf ter he applied for special leave to appeal to this Court and it was granted on 3 10 1950. A short legal argument was advanced on behalf of the appellant based on the language of section 19 (1) of the Act and this is the only point which requires our consideration. The section which consists of two parts is in these terms:\" \"(1) It shall not be lawful for the tenant or any person acting or purporting to act on behalf of the tenant to claim or receive any sum or any consideration as a condi tion for the relinquishment of his tenancy of any premises; 422 (2) Any tenant or person who in contravention of the provisions of sub section (1) receives any sum or considera tion shall, on conviction, be punished with imprisonment for a term which may extend to 6 months and shall also be pun ished with fine which shall not be less than the sum or the value of the consideration received by him.\" It was urged that the offence arises only on receipt of any sum or any consideration as a condition of the relin quishment by a tenant of his tenancy and that in the present case there was no such relinquishment. Exhibit D, which is the most material document, under which the appellant handed over vacant possession of the flat to the complainant, constitutes or evidences an assignment of the tenancy and not a relinquishment. It says : \"I, W.H. King, hereby hand over vacant possession of my flat No. 3 situated on 2nd floor and garage No. 4 on the ground floor of Ganga Vihar Building on Plot No. 55 situated on Marine Drive Road to Mr. Mulchand Kodumal Bhatia from this day onward and that I have no claim whatsoever over this flat and Mr. Mulchand Kodumal Bhatia will pay the rent directly to the landlord.\" The argument raised on behalf of the appellant appears to us to be sound and has to be accepted. The learned Solic itor General urged that 'the word \"relinquishment\" was not a term of art and was used in the section not in any strict technical sense but in its comprehensive meaning as giving up of possession of the premises; and he pointed out that if it was intended by the legislature that \"relinquish ment\" should have the limited meaning sought to be placed upon it on behalf of the appellant, the word \"surrender\" used in the Transfer of Property Act would have been more appropriate. Sections 15 and 18 of the Act were referred to in this connection but in our opinion they lend no assist ance to the argument of the learned counsel. Any sublet ting, assignment or transfer in any other manner of his interest by the tenant is made unlawful under 423 section 15. Section 18 deals with the grant, renewal or continuance of a lease of any premises or the giving of his consent by the landlord to the transfer of a lease by sub lease or otherwise, and it provides that the landlord, who receives any fine, premium, or other like sum or deposit, or any consideration for the grant, renewal or continuance or the accord of consent oh would be guilty of an offence and liable to the punishment therein specified. It would thus be seen that an assignment of the lease or transfer in any other manner by a tenant is not made an offence; the statute merely says that it is not a lawful transaction. It is the landlord's consent to the transfer of a lease by sub lease or otherwise on receipt of consideration that has been made an offence. Then follows section 19 which speaks of the relinquishment of his tenancy of any premises by a tenant. If, by the expression, an assignment such as we have in the present case was meant, appropriate words could have been used, such as the transfer by a tenant of his interest, which we find in section 108, sub clause (i), of the Trans fer of Property Act. The distinction between an assignment on the one hand and relinquishment or surrender on the other is too plain to be ignored. In the case of an assignment, the assignor contin ues to be liable to the landlord for the performance of his obligations under the tenancy and this liability is contrac tual, while the assignee becomes liable by reason of privity of estate. The consent of the landlord to an assignment is not necessary, in the absence of a contract or local usage to the contrary. But in the case of relinquishment, it cannot be a unilateral transaction; it can only be in favour of the lessor by mutual agreement between them. The relin quishment of possession must be to the lessor or one who holds his interest. In fact, a surrender or relinquishment terminates the lessee's rights and lets in the lessor. It is no doubt true that the word \"relinquishment\" does not occur in the Transfer of Property Act but it is found in many of the Tenancy Acts in various provinces where there are Sec tions which deal with the 55 424 relinquishment of their holdings by tenants in favour of the landlord by notice given to him in writing. The section in question, it should be further noted, does not speak of relinquishment or giving up of possession,in general terms. The words are \"the relinquishment of his tenancy of any premises\". The relinquishment of a tenancy is equivalent to surrender by the lessee or tenant of his rights as such. Whether abandonment of a tenancy would come within the meaning of relinquishment is a question that does not arise in this appeal, because in the face of Exhibit D, there is no abandonment in the sense that the tenant disappeared from the scene altogether saying nothing and making no arrange ments about his interest and possession under the lease. As the statute creates an offence and imposes a penalty of fine and imprisonment, the words of the section must be strictly construed in favour of the subject. We are not concerned so much with what might possibly have been intend ed as with what has been actually said in and by the language employed. As in our view, there has been no \"relinquishment\" within the meaning of section 19, sub clause (1), the conviction under sub clause (2) cannot be sustained. It is set aside and the fine of Rs. 30,000 will be refunded if it has al ready been paid. The other parts of the order of the learned Presidency Magistrate, as regards the disposal of Rs. 1,000 paid by the complainant to the appellant and the sum of Rs. 29,500 brought in by the police, will, however, stand. Conviction sit aside. Agent for respondent No. 1: P.A. Mehta. Agent for respondent No. 2: Ganpat Rai..\n",
            "{'rouge-1': {'r': 0.22176308539944903, 'p': 0.8609625668449198, 'f': 0.35268345785982924}, 'rouge-2': {'r': 0.15072830905636478, 'p': 0.6878612716763006, 'f': 0.2472727243240533}, 'rouge-l': {'r': 0.22038567493112948, 'p': 0.8556149732620321, 'f': 0.35049287735599577}}\n"
          ]
        }
      ],
      "source": [
        "# inputs to the model\n",
        "if __name__ == \"__main__\":\n",
        "  FileContent,summaryContent=read_input()\n",
        "  tokenizer,model=model_load()\n",
        "  chunks=chunking(FileContent,tokenizer)\n",
        "  final_summ_gen=sum_generate(chunks,tokenizer,model)\n",
        "  result_rouge=rouge_score(summaryContent,final_summ_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOei4BSRCv8s"
      },
      "source": [
        "If you want to use `BigBirdForCausalLM` as a standalone, add `is_decoder=True.`\n",
        "\n",
        "tokenizer.model_max_length : 4096\n",
        "\n",
        "max tokens excluding the special tokens 4094\n",
        "\n",
        "num_special_tokens_to_add  2  98\n",
        "\n",
        "maximum tokens in longest sentence: 138\n",
        "\n",
        "Total no of chunks created 1\n",
        "\n",
        "Total no of tokens generated by chunks 2571\n",
        "\n",
        "Total no of token in original text 2636\n",
        "\n",
        "No of tokens in each  chunk excluding the special token [2569]\n",
        "\n",
        "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
        "  warnings.warn(\n",
        "**Input length of input_ids is 2571, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.**\n",
        "\n",
        "{'rouge-1': {'r': 0.22176308539944903, 'p': 0.8609625668449198, 'f': 0.35268345785982924}, \n",
        "\n",
        "'rouge-2': {'r': 0.15072830905636478, 'p': 0.6878612716763006, 'f': 0.2472727243240533}, \n",
        "\n",
        "'rouge-l': {'r': 0.22038567493112948, 'p': 0.8556149732620321, 'f': 0.35049287735599577}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "487RwkAeZBue"
      },
      "source": [
        "# BigBird - Chunking (Multiple Documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uUHr5eYLZBuf"
      },
      "outputs": [],
      "source": [
        "def read_input(i):\n",
        "  doc_name = f'/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/judgement/{i}.txt'\n",
        "  doc = open(doc_name,'r')\n",
        "  FileContent = doc.read().strip()\n",
        "  sum_name =f'/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/summary/{i}.txt'\n",
        "  sum = open(sum_name,'r')\n",
        "  summaryContent = sum.read().strip()\n",
        "  return(FileContent,summaryContent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2tSY-YYoZBuf"
      },
      "outputs": [],
      "source": [
        "from transformers import BigBirdForCausalLM\n",
        "\n",
        "def model_load():\n",
        "    checkpoint = \"google/bigbird-roberta-base\" #model loaded from Huggingface\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = BigBirdForCausalLM.from_pretrained(checkpoint,is_decoder=True)\n",
        "#Model Details \n",
        "    #print(\"tokenizer.model_max_length :\",tokenizer.model_max_length )# max token inputted in model 1024\n",
        "    #print(\" max tokens excluding the special tokens\",tokenizer.max_len_single_sentence )# max tokens for input in model 1022\n",
        "    #print(\"num_special_tokens_to_add \",tokenizer.num_special_tokens_to_add() ) # special token needed by model 2\n",
        "    return(tokenizer,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JpBOqVvVZBug"
      },
      "outputs": [],
      "source": [
        "def chunking(FileContent,tokenizer):\n",
        "    # extract the sentences from the document\n",
        "    sentences = nltk.tokenize.sent_tokenize(FileContent) #split the data(paragraph) into individual sentences\n",
        "    #print(len(sentences)) #print total no of sentences\n",
        "    # find the max tokens in the longest sentence\n",
        "    maxtokencount=max([len(tokenizer.tokenize(sentence)) for sentence in sentences])\n",
        "    #print(\"maximum tokens in longest sentence:\",maxtokencount)\n",
        "\n",
        "    # initialize\n",
        "    length = 0\n",
        "    chunk = \"\"\n",
        "    chunks = []\n",
        "    count = -1\n",
        "    for sentence in sentences:\n",
        "        count += 1\n",
        "        combined_length = len(tokenizer.tokenize(sentence)) + length # add the no. of sentence tokens to the length counter\n",
        "        #print(combined_length)  #combined length of all the tokens in all sentences \n",
        "\n",
        "        if combined_length  <= tokenizer.max_len_single_sentence: # if it doesn't exceed than max_len(1022)\n",
        "            chunk += sentence + \" \" # add the sentence to the chunk with white space\n",
        "            length = combined_length # update the length counter\n",
        "\n",
        "            # if it is the last sentence\n",
        "            if count == len(sentences) - 1:\n",
        "                chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        else:   # if max token limit reaches then save the chunk\n",
        "            chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        # reset the parameter to add next tokens to next chunk\n",
        "            length = 0 \n",
        "            chunk = \"\"\n",
        "\n",
        "        # take care of the overflow sentence\n",
        "            chunk += sentence + \" \"\n",
        "            length = len(tokenizer.tokenize(sentence))\n",
        "\n",
        "            \n",
        "    #print(\"Total no of chunks created\",len(chunks))\n",
        "    #print(\"Total no of tokens generated by chunks\",sum([len(tokenizer(c).input_ids) for c in chunks]))\n",
        "    #print(\"Total no of token in original text\",len(tokenizer(FileContent).input_ids))\n",
        "    #print(\"No of tokens in each  chunk excluding the special token\",[len(tokenizer.tokenize(c)) for c in chunks])\n",
        "    return (chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ktGd9xbJZBuh"
      },
      "outputs": [],
      "source": [
        "def sum_generate(chunks,tokenizer,model):\n",
        "    final_summ_gen=\"\"\n",
        "    inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks] #genrating inputs with chunks pt stands for pytorch\n",
        "    for input in inputs:\n",
        "        output = model.generate(**input)    #output generated for each chunk\n",
        "        summ_generated=tokenizer.decode(*output, skip_special_tokens=True)# decoding the output\n",
        "        final_summ_gen= final_summ_gen+summ_generated\n",
        "    #print(final_summ_gen)\n",
        "    return(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KI1ra1RdZBuh"
      },
      "outputs": [],
      "source": [
        "def rouge_score(summaryContent,final_summ_gen):  \n",
        "    rouge = Rouge()\n",
        "    result_rouge=rouge.get_scores(summaryContent, final_summ_gen, avg=True)\n",
        "# Printing the final list\n",
        "    return result_rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7010775c6e464460a52b80290f84db88",
            "a9155f311d38422e86053dbcff2447a0",
            "b1c1f32a2292453384ca299053e55aeb",
            "8e5199f7e7b9483fa87d78530157e7c8",
            "ff03fe04fccd4aefa5afa23099cce2f8",
            "e3d200e47dbb4f7595dae0cdab74a8ec",
            "99d40d0efcf5480d866c76297626fb60",
            "c7ca75f1f2f745bcac3be306c8828072",
            "60da870bb2514a29a7e5759c4fdcee9d",
            "77669810f0424671b5e1f8466f7e55d6",
            "04b37887e7144b1888fc81bf8f41e2fb"
          ]
        },
        "outputId": "f693926f-8716-4eeb-f461-b42cbe2901c3",
        "id": "OlPadthCZBuh"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7010775c6e464460a52b80290f84db88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Input length of input_ids is 4062, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 629, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 629 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 2501, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4079, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 3537, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 2007, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4079, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4085, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4064, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4068, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4040, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 1954, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 2429, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 2565, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4094, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 184, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 184 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 3109, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 1730, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4095, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 2501, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4034, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 284, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 284 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 2758, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 2557, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4085, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 1203, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 1535, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 1679, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4051, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4090, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 231, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 231 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 3566, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4087, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 264, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 264 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 1845, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4093, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 9 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4068, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 3365, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4071, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 3961, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4088, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 689, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 689 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4053, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 329, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 329 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4054, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4066, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 276, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 276 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 3532, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4059, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4084, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4094, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 4032, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 1834, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 1060, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForCausalLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Input length of input_ids is 4090, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "Input length of input_ids is 3248, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        }
      ],
      "source": [
        "# inputs to the model\n",
        "if __name__ == \"__main__\":\n",
        "  result_rouge_list = []\n",
        "  for i in dir_list[:30]:\n",
        "    FileContent,summaryContent=read_input(i)\n",
        "    tokenizer,model=model_load()\n",
        "    chunks=chunking(FileContent,tokenizer)\n",
        "    final_summ_gen=sum_generate(chunks,tokenizer,model)\n",
        "    result_rouge_list.append(rouge_score(summaryContent,final_summ_gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e5471a-b5e7-4350-8524-0c20e352744b",
        "id": "ynI-ah96ZBui"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(result_rouge_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d41ff4f-52b2-418e-f5fe-4bdfe545f595",
        "id": "-vdD9XFCZBui"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge-1': {'r': 0.29704686623815646, 'p': 0.8199397745193063, 'f': 0.4288183742015664}, 'rouge-2': {'r': 0.18563868603051248, 'p': 0.651633184874414, 'f': 0.28231233567068204}, 'rouge-l': {'r': 0.28884331556801657, 'p': 0.7956824084144307, 'f': 0.41679113893456854}}\n"
          ]
        }
      ],
      "source": [
        "agg_rouge_score = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye22-Qw96uPO"
      },
      "source": [
        "# BERT - Chunking (Single Document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOrnifDM6uPP"
      },
      "outputs": [],
      "source": [
        "def read_input():\n",
        "  doc_name = '/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/judgement/78.txt'\n",
        "  doc = open(doc_name,'r')\n",
        "  FileContent = doc.read().strip()\n",
        "  sum_name ='/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/summary/78.txt'\n",
        "  sum = open(sum_name,'r')\n",
        "  summaryContent = sum.read().strip()\n",
        "  return(FileContent,summaryContent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN19ehmX8F7d"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "def model_load():\n",
        "    checkpoint = \"bert-base-uncased\" #model loaded from Huggingface\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "    tokenizer.bos_token = tokenizer.cls_token\n",
        "    tokenizer.eos_token = tokenizer.sep_token\n",
        "    model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")\n",
        "    model.config.vocab_size = model.config.decoder.vocab_size\n",
        "    model.config.max_length = 142\n",
        "    model.config.min_length = 56\n",
        "    model.config.no_repeat_ngram_size = 3\n",
        "    model.config.early_stopping = True\n",
        "    model.config.length_penalty = 2.0\n",
        "    model.config.num_beams = 4\n",
        "#Model Details \n",
        "    print(\"tokenizer.model_max_length :\",tokenizer.model_max_length )# max token inputted in model 1024\n",
        "    print(\" max tokens excluding the special tokens\",tokenizer.max_len_single_sentence )# max tokens for input in model 1022\n",
        "    print(\"num_special_tokens_to_add \",tokenizer.num_special_tokens_to_add() ) # special token needed by model 2\n",
        "    return(tokenizer,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYlv_TU-6uPQ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "def chunking(FileContent,tokenizer):\n",
        "    # extract the sentences from the document\n",
        "    sentences = nltk.tokenize.sent_tokenize(FileContent) #split the data(paragraph) into individual sentences\n",
        "    print(len(sentences)) #print total no of sentences\n",
        "    # find the max tokens in the longest sentence\n",
        "    maxtokencount=max([len(tokenizer.tokenize(sentence)) for sentence in sentences])\n",
        "    print(\"maximum tokens in longest sentence:\",maxtokencount)\n",
        "\n",
        "    # initialize\n",
        "    length = 0\n",
        "    chunk = \"\"\n",
        "    chunks = []\n",
        "    count = -1\n",
        "    for sentence in sentences:\n",
        "        count += 1\n",
        "        combined_length = len(tokenizer.tokenize(sentence)) + length # add the no. of sentence tokens to the length counter\n",
        "        #print(combined_length)  #combined length of all the tokens in all sentences \n",
        "\n",
        "        if combined_length  <= tokenizer.max_len_single_sentence: # if it doesn't exceed than max_len(1022)\n",
        "            chunk += sentence + \" \" # add the sentence to the chunk with white space\n",
        "            length = combined_length # update the length counter\n",
        "\n",
        "            # if it is the last sentence\n",
        "            if count == len(sentences) - 1:\n",
        "                chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        else:   # if max token limit reaches then save the chunk\n",
        "            chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        # reset the parameter to add next tokens to next chunk\n",
        "            length = 0 \n",
        "            chunk = \"\"\n",
        "\n",
        "        # take care of the overflow sentence\n",
        "            chunk += sentence + \" \"\n",
        "            length = len(tokenizer.tokenize(sentence))\n",
        "\n",
        "            \n",
        "    print(\"Total no of chunks created\",len(chunks))\n",
        "    print(\"Total no of tokens generated by chunks\",sum([len(tokenizer(c).input_ids) for c in chunks]))\n",
        "    print(\"Total no of token in original text\",len(tokenizer(FileContent).input_ids))\n",
        "    print(\"No of tokens in each  chunk excluding the special token\",[len(tokenizer.tokenize(c)) for c in chunks])\n",
        "    return (chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UteqkIHO6uPR"
      },
      "outputs": [],
      "source": [
        "def sum_generate(chunks,tokenizer,model):\n",
        "    final_summ_gen=\"\"\n",
        "    inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks] #genrating inputs with chunks pt stands for pytorch\n",
        "    for input in inputs:\n",
        "        output = model.generate(**input)    #output generated for each chunk\n",
        "        summ_generated=tokenizer.decode(*output, skip_special_tokens=True)# decoding the output\n",
        "        final_summ_gen= final_summ_gen+summ_generated\n",
        "    return(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDHxcY4o6uPR"
      },
      "outputs": [],
      "source": [
        "def rouge_score(summaryContent,final_summ_gen):  \n",
        "    rouge = Rouge()\n",
        "    result_rouge=rouge.get_scores(summaryContent, final_summ_gen, avg=True)\n",
        "# Printing the final list\n",
        "    print(result_rouge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "nzEeGVWY6uPR",
        "outputId": "db94e2c6-f9a6-442f-e998-860ad0ba1b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2665 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer.model_max_length : 512\n",
            " max tokens excluding the special tokens 510\n",
            "num_special_tokens_to_add  2\n",
            "98\n",
            "maximum tokens in longest sentence: 147\n",
            "Total no of chunks created 6\n",
            "Total no of tokens generated by chunks 2675\n",
            "Total no of token in original text 2665\n",
            "No of tokens in each  chunk excluding the special token [489, 487, 494, 493, 488, 212]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-62b8cf56df5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mchunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileContent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mfinal_summ_gen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mresult_rouge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrouge_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaryContent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_summ_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-ae37fe9d7cc0>\u001b[0m in \u001b[0;36msum_generate\u001b[0;34m(chunks, tokenizer, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#genrating inputs with chunks pt stands for pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#output generated for each chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msumm_generated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# decoding the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfinal_summ_gen\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfinal_summ_gen\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msumm_generated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mgeneration_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmodel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# All unused kwargs must be model kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_model_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;31m# 2. Set generation parameters if not already defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_model_kwargs\u001b[0;34m(self, model_kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munused_model_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1091\u001b[0m                 \u001b[0;34mf\"The following `model_kwargs` are not used by the model: {unused_model_args} (note: typos in the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0;34m\" generate arguments will also show up in this list)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The following `model_kwargs` are not used by the model: ['token_type_ids'] (note: typos in the generate arguments will also show up in this list)"
          ]
        }
      ],
      "source": [
        "# inputs to the model\n",
        "if __name__ == \"__main__\":\n",
        "  FileContent,summaryContent=read_input()\n",
        "  tokenizer,model=model_load()\n",
        "  chunks=chunking(FileContent,tokenizer)\n",
        "  final_summ_gen=sum_generate(chunks,tokenizer,model)\n",
        "  result_rouge=rouge_score(summaryContent,final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl5zoy-V6uPS",
        "outputId": "4c95df09-8217-4556-e316-bda8538cdae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Appeal from an Order of the High Court of Bombay (Bavdekar and Chainani JJ.) dated 20th February, 1950, in Criminal Appeal No. 106 of 1950. W.H. King was tenant of a flat on the second floor of a building called \"Ganga Vihar\", Marine Drive, Bombay, which belongs to a lady named Durgeshwari Devi. The wife of the appellant denied any aiding and abetting. The wife was acquitted, the evidence being insufficient to prove any abetment. The appellant preferred an appeal to the High Court of Bombay but it was summarily dismissed. He asked for a certificate under article 134(1)(c) of the Constitution but this was rejected on 10 4 1950. He applied for special leave to appeal to this Court and it was granted on 3 10 1950. The word \"relinquishment\" does not occur in the Transfer of Property Act but it is found in many of the Tenancy Acts in various provinces where there are Sec tions which deal with the relinquishment of their holdings by tenants in favour of the landlord by notice given to him in writing. The conviction under sub clause (2) cannot be sustained, the conviction is set aside and the fine of Rs. 30,000 will be refunded if it has been paid.\n"
          ]
        }
      ],
      "source": [
        "print(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjTZ5Bi06uPS",
        "outputId": "32c25221-1f30-4fce-82a9-f6ff8c8961a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given Summary: Sub section (1) of sec.\n",
            "19 of the Bombay Rents, Hotel and Lodging House Rates Control Act, LVI I of 1947, provided that \"it shall not be lawful for the tenant or any person acting or purporting to act on behalf of the tenant to claim or receive any sum or any consideration as a condition for the relinquishment of his tenancy of any premises\"; and sub sec.\n",
            "(2) provided that any tenant or person who in contravention of the provisions of sub sec.\n",
            "(1) receives any sum or consideration shall on conviction be punished with imprisonment and also with fine.\n",
            "A. who was a tenant of a flat, handed over vacant posses sion the flat to B on receiving \"pugree\", under a document which recited that A shall have no claim whatever over the flat and that B shall pay the rent directly to the landlord.\n",
            "A was convicted of an offence under sec.\n",
            "19 (2).\n",
            "Held, that there was no \"relinquishment\" of his tenancy by A, within the meaning of sec.\n",
            "19 (1) and the conviction could not be sustained.\n",
            "There is a clear distinction between an assignment of a tenancy on the one hand and a relinquishment or surrender on the other.\n",
            "In the case of an assignment, the assignor con tinues to be liable to the landlord for the performance of his obligations under the tenancy and this liability is contractual, while the assignee becomes liable by reason of privity of estate.\n",
            "The consent of the landlord to an as signment is not necessary, in the absence of a contract or local usage to the contrary.\n",
            "But in the case of relinquish ment it cannot be a unilateral transaction; it can only be in favour of the lessor by mutual agreement between them.\n",
            "Relinquishment of possession must be to the lessor or one who holds his interest; and surrender or relinquishment terminates the lessee 's rights and lets in the lessor.\n",
            "As sec.\n",
            "19 of Bombay Act LVII of 1947 creates an offence and imposes a penalty of fine and imprisonment, the words of the section must be strictly construed in favour of the subject.\n",
            "The Court is not concerned so much with what might possibly have been intended as with what has been actually said in and by the language employed in the statute.\n",
            "Judgment of the Bombay High Court reversed.\n"
          ]
        }
      ],
      "source": [
        "print(\"Given Summary:\",summaryContent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJIk7vLi6uPS"
      },
      "source": [
        "tokenizer.model_max_length : 1024\n",
        "\n",
        "max tokens excluding the special tokens 1022\n",
        "\n",
        "num_special_tokens_to_add  2  98\n",
        "\n",
        "maximum tokens in longest sentence: 137\n",
        "\n",
        "Total no of chunks created 3\n",
        "\n",
        "Total no of tokens generated by chunks 2572\n",
        "\n",
        "Total no of token in original text 2634\n",
        "\n",
        "No of tokens in each  chunk excluding the special token [999, 1019, 548]\n",
        "\n",
        "\n",
        "\n",
        "{'rouge-1': {'r': 0.291044776119403, 'p': 0.20855614973262032, 'f': 0.24299064934191253}, \n",
        "\n",
        "'rouge-2': {'r': 0.08673469387755102, 'p': 0.049132947976878616, 'f': 0.06273062268923388}, \n",
        "\n",
        "'rouge-l': {'r': 0.26119402985074625, 'p': 0.18716577540106952, 'f': 0.21806853096185025}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntyr2-CvAAUX"
      },
      "source": [
        "# T5 Small - Chunking (Single Document)\n",
        "T5 Small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0bQVWRTAAUt"
      },
      "outputs": [],
      "source": [
        "def read_input():\n",
        "  doc_name = '/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/judgement/232.txt'\n",
        "  doc = open(doc_name,'r')\n",
        "  FileContent = doc.read().strip()\n",
        "  sum_name ='/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/summary/232.txt'\n",
        "  sum = open(sum_name,'r')\n",
        "  summaryContent = sum.read().strip()\n",
        "  return(FileContent,summaryContent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZQMJaOyAAUu"
      },
      "outputs": [],
      "source": [
        "def model_load():\n",
        "    checkpoint = \"t5-small\" #model loaded from Huggingface\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "#Model Details \n",
        "    print(\"tokenizer.model_max_length :\",tokenizer.model_max_length )# max token inputted in model 1024\n",
        "    print(\" max tokens excluding the special tokens\",tokenizer.max_len_single_sentence )# max tokens for input in model 1022\n",
        "    print(\"num_special_tokens_to_add \",tokenizer.num_special_tokens_to_add() ) # special token needed by model 2\n",
        "    return(tokenizer,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60qxtacnAAUv"
      },
      "outputs": [],
      "source": [
        "def chunking(FileContent,tokenizer):\n",
        "    # extract the sentences from the document\n",
        "    sentences = nltk.tokenize.sent_tokenize(FileContent) #split the data(paragraph) into individual sentences\n",
        "    print(len(sentences)) #print total no of sentences\n",
        "    # find the max tokens in the longest sentence\n",
        "    maxtokencount=max([len(tokenizer.tokenize(sentence)) for sentence in sentences])\n",
        "    print(\"maximum tokens in longest sentence:\",maxtokencount)\n",
        "\n",
        "    # initialize\n",
        "    length = 0\n",
        "    chunk = \"\"\n",
        "    chunks = []\n",
        "    count = -1\n",
        "    for sentence in sentences:\n",
        "        count += 1\n",
        "        combined_length = len(tokenizer.tokenize(sentence)) + length # add the no. of sentence tokens to the length counter\n",
        "        #print(combined_length)  #combined length of all the tokens in all sentences \n",
        "\n",
        "        if combined_length  <= tokenizer.max_len_single_sentence: # if it doesn't exceed than max_len(1022)\n",
        "            chunk += sentence + \" \" # add the sentence to the chunk with white space\n",
        "            length = combined_length # update the length counter\n",
        "\n",
        "            # if it is the last sentence\n",
        "            if count == len(sentences) - 1:\n",
        "                chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        else:   # if max token limit reaches then save the chunk\n",
        "            chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        # reset the parameter to add next tokens to next chunk\n",
        "            length = 0 \n",
        "            chunk = \"\"\n",
        "\n",
        "        # take care of the overflow sentence\n",
        "            chunk += sentence + \" \"\n",
        "            length = len(tokenizer.tokenize(sentence))\n",
        "\n",
        "            \n",
        "    print(\"Total no of chunks created\",len(chunks))\n",
        "    print(\"Total no of tokens generated by chunks\",sum([len(tokenizer(c).input_ids) for c in chunks]))\n",
        "    print(\"Total no of token in original text\",len(tokenizer(FileContent).input_ids))\n",
        "    print(\"No of tokens in each  chunk excluding the special token\",[len(tokenizer.tokenize(c)) for c in chunks])\n",
        "    return (chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdfrbgJJAAUw"
      },
      "outputs": [],
      "source": [
        "def sum_generate(chunks,tokenizer,model):\n",
        "    final_summ_gen=\"\"\n",
        "    inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks] #genrating inputs with chunks pt stands for pytorch\n",
        "    for input in inputs:\n",
        "        output = model.generate(**input)    #output generated for each chunk\n",
        "        summ_generated=tokenizer.decode(*output, skip_special_tokens=True)# decoding the output\n",
        "        final_summ_gen= final_summ_gen+summ_generated\n",
        "    return(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w69B6UEPAAUx"
      },
      "outputs": [],
      "source": [
        "def rouge_score(summaryContent,final_summ_gen):  \n",
        "    rouge = Rouge()\n",
        "    result_rouge=rouge.get_scores(summaryContent, final_summ_gen, avg=True)\n",
        "# Printing the final list\n",
        "    print(result_rouge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492,
          "referenced_widgets": [
            "2c6b40a90e7a4711adf599b46d773635",
            "d62b57bfec074e9a8a072599a327293e",
            "709a450908c84c0081a6f6ba6e136666",
            "2e82a44966564a10be502396b354d2e2",
            "15651b1a2c5c4b41ad458b58e3f4e6ee",
            "f55476c81e17435d9ff1c2267d07c14c",
            "800d1a1d62f044a3b14fbb935758af6b",
            "6c83647866a2429da0bfc1e7c480b2fc",
            "6e3f1a7ad7ef46b38d0742b27dc61fab",
            "48ed33128c274878a958d3ccfb66accd",
            "3c7448998c794a448295b0bafbac05e7",
            "cfb5ca21d3a34d7fa6da28ba8411ef2a",
            "98858911ab784c028d7d261116d384a9",
            "ac2d20f9694a4079a1d2ee0edfbad543",
            "e444f793a5ea47559bfa053a84e1eaec",
            "a4a074620d6e443abe9bc9b38a303a5c",
            "27460488413f45328aa496efd949c0ba",
            "a8e0803eac484d998a15a5a5a2a36197",
            "2316f12a61074bd68253d66798ad5893",
            "7b18347ae13f451fa75fc6c3018b6ac2",
            "27ed98c3550048a9803439920134bd63",
            "ac56aaa8dbdb400193f6f3dfb833572f",
            "2ab0bd75b12143558f8da9a5ff4f8478",
            "03f0bb47bc874f15b2c1e4b708e7e03f",
            "7faab6520b2945c9b4a1077783fd3096",
            "c3844dfa31f446d0b2e51e0eee454612",
            "10fdf589e2d94f98bcb338ff4d059a85",
            "f8d78cc483ab4849aacd5db010d44d43",
            "da6a976fdeb64d578f9cc870c3117b8d",
            "9f909b30ad9b4fa498737619f767e7ee",
            "cec011865f0042cfaf898222d29fb359",
            "d69504e6293c4512b942593c2c495111",
            "5e40905d5a594ca3b042cd63150f1a18",
            "ceab81b29ac54155b94ae0f8dec96e73",
            "cbc2202c5bb6415da0a86e3a275983ef",
            "182a0427955b4ac686018722bd5609e6",
            "b425e1c736ad416b949bbbde5ba61c25",
            "ba7407f3dafd4d30b32b6ff29b8de188",
            "8b8d6511530846cfb289df4374affa06",
            "2941bba83cd24424ab920986f752ace4",
            "891ea26c59e84bd49734ed8aa4b324d0",
            "ddca2744693b48b382bbfa8b3d022713",
            "7488502eb2d743e4ab7c11e9b4e38814",
            "5a15a5ff968e43d5a98eb758b11f2fb1",
            "544d3bcf1ca743d3ab2a4dd4d7b07e6c",
            "39849b525bbd42f783bf4f477a927b79",
            "f8cd81e8f43b4f36bc252e3041bef7f8",
            "6588bd84bdd2458d945137a16007f5e8",
            "63b19e775a044348a1d8d6269d9b9119",
            "f2c2a2d1898444f98110f81990a3d8ed",
            "25329a3d204643eabac4589bcb8243c9",
            "0259dce322bc4e879aab1a361d810348",
            "46f7f69ff2d64d1a87fcca0ac2926454",
            "4209339e5eb8438f9652460deae21c6b",
            "8b3efd4090154047827ca7ad703bf499"
          ]
        },
        "id": "NAapb8nlE3B6",
        "outputId": "4e37b3b7-4972-4992-faaa-3b5d7a81ff67"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c6b40a90e7a4711adf599b46d773635",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfb5ca21d3a34d7fa6da28ba8411ef2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ab0bd75b12143558f8da9a5ff4f8478",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ceab81b29ac54155b94ae0f8dec96e73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "544d3bcf1ca743d3ab2a4dd4d7b07e6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer.model_max_length : 512\n",
            " max tokens excluding the special tokens 511\n",
            "num_special_tokens_to_add  1\n",
            "860\n",
            "maximum tokens in longest sentence: 198\n",
            "Total no of chunks created 78\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (37431 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total no of tokens generated by chunks 37508\n",
            "Total no of token in original text 37431\n",
            "No of tokens in each  chunk excluding the special token [470, 502, 505, 511, 500, 500, 471, 494, 503, 472, 465, 483, 507, 511, 491, 492, 502, 475, 474, 410, 473, 473, 456, 478, 487, 456, 475, 447, 497, 472, 488, 502, 506, 509, 476, 492, 504, 435, 509, 484, 501, 463, 499, 506, 486, 511, 505, 492, 492, 505, 502, 421, 479, 488, 494, 468, 480, 498, 494, 480, 452, 490, 494, 499, 445, 482, 423, 506, 498, 449, 496, 371, 499, 502, 509, 503, 445, 246]\n",
            "{'rouge-1': {'r': 0.42317380352644834, 'p': 0.27495908346972175, 'f': 0.3333333285586932}, 'rouge-2': {'r': 0.16604708798017348, 'p': 0.09824046920821114, 'f': 0.1234454121877156}, 'rouge-l': {'r': 0.380352644836272, 'p': 0.24713584288052373, 'f': 0.29960316982853447}}\n"
          ]
        }
      ],
      "source": [
        "# inputs to the model\n",
        "if __name__ == \"__main__\":\n",
        "  FileContent,summaryContent=read_input()\n",
        "  tokenizer,model=model_load()\n",
        "  chunks=chunking(FileContent,tokenizer)\n",
        "  final_summ_gen=sum_generate(chunks,tokenizer,model)\n",
        "  result_rouge=rouge_score(summaryContent,final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_C7u1l3AAUy",
        "outputId": "688fc4d3-113f-4782-a73e-3788f334eafc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "of the Court of Appeal, arising out of an order dated 20th February,,,, and the keys of the flat and the motor garage were handed overthe appellant was in search of a partner to carry on his business. thea tion for the relinquishment of his tenancy of anyis not a lawful transaction; it cannot be a unilateral transaction. of a tenancy is equivalent to surrender by the lessee or tenant of his\n"
          ]
        }
      ],
      "source": [
        "print(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtyGKsp7AAUy",
        "outputId": "e5703856-1062-42e8-cbef-909e16dec7dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given Summary: Sub section (1) of sec.\n",
            "19 of the Bombay Rents, Hotel and Lodging House Rates Control Act, LVI I of 1947, provided that \"it shall not be lawful for the tenant or any person acting or purporting to act on behalf of the tenant to claim or receive any sum or any consideration as a condition for the relinquishment of his tenancy of any premises\"; and sub sec.\n",
            "(2) provided that any tenant or person who in contravention of the provisions of sub sec.\n",
            "(1) receives any sum or consideration shall on conviction be punished with imprisonment and also with fine.\n",
            "A. who was a tenant of a flat, handed over vacant posses sion the flat to B on receiving \"pugree\", under a document which recited that A shall have no claim whatever over the flat and that B shall pay the rent directly to the landlord.\n",
            "A was convicted of an offence under sec.\n",
            "19 (2).\n",
            "Held, that there was no \"relinquishment\" of his tenancy by A, within the meaning of sec.\n",
            "19 (1) and the conviction could not be sustained.\n",
            "There is a clear distinction between an assignment of a tenancy on the one hand and a relinquishment or surrender on the other.\n",
            "In the case of an assignment, the assignor con tinues to be liable to the landlord for the performance of his obligations under the tenancy and this liability is contractual, while the assignee becomes liable by reason of privity of estate.\n",
            "The consent of the landlord to an as signment is not necessary, in the absence of a contract or local usage to the contrary.\n",
            "But in the case of relinquish ment it cannot be a unilateral transaction; it can only be in favour of the lessor by mutual agreement between them.\n",
            "Relinquishment of possession must be to the lessor or one who holds his interest; and surrender or relinquishment terminates the lessee 's rights and lets in the lessor.\n",
            "As sec.\n",
            "19 of Bombay Act LVII of 1947 creates an offence and imposes a penalty of fine and imprisonment, the words of the section must be strictly construed in favour of the subject.\n",
            "The Court is not concerned so much with what might possibly have been intended as with what has been actually said in and by the language employed in the statute.\n",
            "Judgment of the Bombay High Court reversed.\n"
          ]
        }
      ],
      "source": [
        "print(\"Given Summary:\",summaryContent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmDhUW85AxY1"
      },
      "source": [
        "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
        "\n",
        "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
        "\n",
        "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
        "\n",
        "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
        "\n",
        "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
        "  warnings.warn("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDglWLPEA0QR"
      },
      "source": [
        "Token indices sequence length is longer than the specified maximum sequence length for this model (2859 > 512). Running this sequence through the model will result in indexing errors\n",
        "\n",
        "tokenizer.model_max_length : 512\n",
        "\n",
        "max tokens excluding the special tokens 511\n",
        "\n",
        "num_special_tokens_to_add  1  98\n",
        "\n",
        "maximum tokens in longest sentence: 147\n",
        "\n",
        "Total no of chunks created 6\n",
        "\n",
        "Total no of tokens generated by chunks 2864\n",
        "\n",
        "Total no of token in original text 2859\n",
        "\n",
        "No of tokens in each  chunk excluding the special token [502, 498, 398, 496, 489, 475]\n",
        "\n",
        "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
        "\n",
        "{'rouge-1': {'r': 0.5686274509803921, 'p': 0.15508021390374332, 'f': 0.24369747562424976}, \n",
        "\n",
        "'rouge-2': {'r': 0.31343283582089554, 'p': 0.06069364161849711, 'f': 0.10169491253604121},\n",
        "\n",
        "'rouge-l': {'r': 0.47058823529411764, 'p': 0.12834224598930483, 'f': 0.2016806689015607}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAQaa3UL1gKb"
      },
      "source": [
        "# T5 Small - Chunking (Multiple Documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS9Hbm8s1gKc"
      },
      "outputs": [],
      "source": [
        "def read_input(i):\n",
        "  doc_name = f'/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/judgement/{i}.txt'\n",
        "  doc = open(doc_name,'r')\n",
        "  FileContent = doc.read().strip()\n",
        "  sum_name =f'/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/test-data/summary/{i}.txt'\n",
        "  sum = open(sum_name,'r')\n",
        "  summaryContent = sum.read().strip()\n",
        "  return(FileContent,summaryContent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtc7eGsi1gKc"
      },
      "outputs": [],
      "source": [
        "def model_load():\n",
        "    checkpoint = \"t5-small\" #model loaded from Huggingface\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "#Model Details \n",
        "    #print(\"tokenizer.model_max_length :\",tokenizer.model_max_length )# max token inputted in model 1024\n",
        "    #print(\" max tokens excluding the special tokens\",tokenizer.max_len_single_sentence )# max tokens for input in model 1022\n",
        "    #print(\"num_special_tokens_to_add \",tokenizer.num_special_tokens_to_add() ) # special token needed by model 2\n",
        "    return(tokenizer,model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOKGtq0x1gKd"
      },
      "outputs": [],
      "source": [
        "def chunking(FileContent,tokenizer):\n",
        "    # extract the sentences from the document\n",
        "    sentences = nltk.tokenize.sent_tokenize(FileContent) #split the data(paragraph) into individual sentences\n",
        "    #print(len(sentences)) #print total no of sentences\n",
        "    # find the max tokens in the longest sentence\n",
        "    maxtokencount=max([len(tokenizer.tokenize(sentence)) for sentence in sentences])\n",
        "    #print(\"maximum tokens in longest sentence:\",maxtokencount)\n",
        "\n",
        "    # initialize\n",
        "    length = 0\n",
        "    chunk = \"\"\n",
        "    chunks = []\n",
        "    count = -1\n",
        "    for sentence in sentences:\n",
        "        count += 1\n",
        "        combined_length = len(tokenizer.tokenize(sentence)) + length # add the no. of sentence tokens to the length counter\n",
        "        #print(combined_length)  #combined length of all the tokens in all sentences \n",
        "\n",
        "        if combined_length  <= tokenizer.max_len_single_sentence: # if it doesn't exceed than max_len(1022)\n",
        "            chunk += sentence + \" \" # add the sentence to the chunk with white space\n",
        "            length = combined_length # update the length counter\n",
        "\n",
        "            # if it is the last sentence\n",
        "            if count == len(sentences) - 1:\n",
        "                chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        else:   # if max token limit reaches then save the chunk\n",
        "            chunks.append(chunk.strip()) # save the chunk\n",
        "    \n",
        "        # reset the parameter to add next tokens to next chunk\n",
        "            length = 0 \n",
        "            chunk = \"\"\n",
        "\n",
        "        # take care of the overflow sentence\n",
        "            chunk += sentence + \" \"\n",
        "            length = len(tokenizer.tokenize(sentence))\n",
        "\n",
        "            \n",
        "    #print(\"Total no of chunks created\",len(chunks))\n",
        "    #print(\"Total no of tokens generated by chunks\",sum([len(tokenizer(c).input_ids) for c in chunks]))\n",
        "    #print(\"Total no of token in original text\",len(tokenizer(FileContent).input_ids))\n",
        "    #print(\"No of tokens in each  chunk excluding the special token\",[len(tokenizer.tokenize(c)) for c in chunks])\n",
        "    return (chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCtSpBF71gKe"
      },
      "outputs": [],
      "source": [
        "def sum_generate(chunks,tokenizer,model):\n",
        "    final_summ_gen=\"\"\n",
        "    inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks] #genrating inputs with chunks pt stands for pytorch\n",
        "    for input in inputs:\n",
        "        output = model.generate(**input)    #output generated for each chunk\n",
        "        summ_generated=tokenizer.decode(*output, skip_special_tokens=True)# decoding the output\n",
        "        final_summ_gen= final_summ_gen+summ_generated\n",
        "    #print(final_summ_gen)\n",
        "    return(final_summ_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1fyGWTb1gKe"
      },
      "outputs": [],
      "source": [
        "def rouge_score(summaryContent,final_summ_gen):  \n",
        "    rouge = Rouge()\n",
        "    result_rouge=rouge.get_scores(summaryContent, final_summ_gen, avg=True)\n",
        "# Printing the final list\n",
        "    return result_rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5iojC481gKe"
      },
      "outputs": [],
      "source": [
        "# inputs to the model\n",
        "if __name__ == \"__main__\":\n",
        "  result_rouge_list = []\n",
        "  for i in dir_list:\n",
        "    FileContent,summaryContent=read_input(i)\n",
        "    tokenizer,model=model_load()\n",
        "    chunks=chunking(FileContent,tokenizer)\n",
        "    final_summ_gen=sum_generate(chunks,tokenizer,model)\n",
        "    result_rouge_list.append(rouge_score(summaryContent,final_summ_gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR9AnrvwEU3o",
        "outputId": "7b63e1c5-fa06-4346-f811-2ef154d3add2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(result_rouge_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzooBI5y1gKf",
        "outputId": "a1df7862-fede-4061-806c-f16b5bbc5fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge-1': {'r': 0.5340070793670784, 'p': 0.15040051883404526, 'f': 0.2259315977833998}, 'rouge-2': {'r': 0.2703121170814129, 'p': 0.052595345376596325, 'f': 0.08455800139639953}, 'rouge-l': {'r': 0.4836286813566721, 'p': 0.13425102682810058, 'f': 0.20248698625877598}}\n"
          ]
        }
      ],
      "source": [
        "agg_rouge_score = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tnQjcfx2Cv78",
        "IAQaa3UL1gKb"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0259dce322bc4e879aab1a361d810348": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f0bb47bc874f15b2c1e4b708e7e03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d78cc483ab4849aacd5db010d44d43",
            "placeholder": "​",
            "style": "IPY_MODEL_da6a976fdeb64d578f9cc870c3117b8d",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "10fdf589e2d94f98bcb338ff4d059a85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15651b1a2c5c4b41ad458b58e3f4e6ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "182a0427955b4ac686018722bd5609e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_891ea26c59e84bd49734ed8aa4b324d0",
            "max": 2950825948,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddca2744693b48b382bbfa8b3d022713",
            "value": 2950825948
          }
        },
        "2316f12a61074bd68253d66798ad5893": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25329a3d204643eabac4589bcb8243c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27460488413f45328aa496efd949c0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27ed98c3550048a9803439920134bd63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2941bba83cd24424ab920986f752ace4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ab0bd75b12143558f8da9a5ff4f8478": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03f0bb47bc874f15b2c1e4b708e7e03f",
              "IPY_MODEL_7faab6520b2945c9b4a1077783fd3096",
              "IPY_MODEL_c3844dfa31f446d0b2e51e0eee454612"
            ],
            "layout": "IPY_MODEL_10fdf589e2d94f98bcb338ff4d059a85"
          }
        },
        "2c6b40a90e7a4711adf599b46d773635": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d62b57bfec074e9a8a072599a327293e",
              "IPY_MODEL_709a450908c84c0081a6f6ba6e136666",
              "IPY_MODEL_2e82a44966564a10be502396b354d2e2"
            ],
            "layout": "IPY_MODEL_15651b1a2c5c4b41ad458b58e3f4e6ee"
          }
        },
        "2e82a44966564a10be502396b354d2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ed33128c274878a958d3ccfb66accd",
            "placeholder": "​",
            "style": "IPY_MODEL_3c7448998c794a448295b0bafbac05e7",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 38.5kB/s]"
          }
        },
        "39849b525bbd42f783bf4f477a927b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2c2a2d1898444f98110f81990a3d8ed",
            "placeholder": "​",
            "style": "IPY_MODEL_25329a3d204643eabac4589bcb8243c9",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "3c7448998c794a448295b0bafbac05e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4209339e5eb8438f9652460deae21c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f7f69ff2d64d1a87fcca0ac2926454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48ed33128c274878a958d3ccfb66accd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "544d3bcf1ca743d3ab2a4dd4d7b07e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39849b525bbd42f783bf4f477a927b79",
              "IPY_MODEL_f8cd81e8f43b4f36bc252e3041bef7f8",
              "IPY_MODEL_6588bd84bdd2458d945137a16007f5e8"
            ],
            "layout": "IPY_MODEL_63b19e775a044348a1d8d6269d9b9119"
          }
        },
        "5a15a5ff968e43d5a98eb758b11f2fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e40905d5a594ca3b042cd63150f1a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63b19e775a044348a1d8d6269d9b9119": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6588bd84bdd2458d945137a16007f5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4209339e5eb8438f9652460deae21c6b",
            "placeholder": "​",
            "style": "IPY_MODEL_8b3efd4090154047827ca7ad703bf499",
            "value": " 147/147 [00:00&lt;00:00, 4.01kB/s]"
          }
        },
        "6c83647866a2429da0bfc1e7c480b2fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3f1a7ad7ef46b38d0742b27dc61fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "709a450908c84c0081a6f6ba6e136666": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c83647866a2429da0bfc1e7c480b2fc",
            "max": 1209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e3f1a7ad7ef46b38d0742b27dc61fab",
            "value": 1209
          }
        },
        "7488502eb2d743e4ab7c11e9b4e38814": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b18347ae13f451fa75fc6c3018b6ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7faab6520b2945c9b4a1077783fd3096": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f909b30ad9b4fa498737619f767e7ee",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cec011865f0042cfaf898222d29fb359",
            "value": 1389353
          }
        },
        "800d1a1d62f044a3b14fbb935758af6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "891ea26c59e84bd49734ed8aa4b324d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3efd4090154047827ca7ad703bf499": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b8d6511530846cfb289df4374affa06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98858911ab784c028d7d261116d384a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27460488413f45328aa496efd949c0ba",
            "placeholder": "​",
            "style": "IPY_MODEL_a8e0803eac484d998a15a5a5a2a36197",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "9f909b30ad9b4fa498737619f767e7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a074620d6e443abe9bc9b38a303a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e0803eac484d998a15a5a5a2a36197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac2d20f9694a4079a1d2ee0edfbad543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2316f12a61074bd68253d66798ad5893",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b18347ae13f451fa75fc6c3018b6ac2",
            "value": 791656
          }
        },
        "ac56aaa8dbdb400193f6f3dfb833572f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b425e1c736ad416b949bbbde5ba61c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7488502eb2d743e4ab7c11e9b4e38814",
            "placeholder": "​",
            "style": "IPY_MODEL_5a15a5ff968e43d5a98eb758b11f2fb1",
            "value": " 2.95G/2.95G [00:23&lt;00:00, 171MB/s]"
          }
        },
        "ba7407f3dafd4d30b32b6ff29b8de188": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3844dfa31f446d0b2e51e0eee454612": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d69504e6293c4512b942593c2c495111",
            "placeholder": "​",
            "style": "IPY_MODEL_5e40905d5a594ca3b042cd63150f1a18",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 3.49MB/s]"
          }
        },
        "cbc2202c5bb6415da0a86e3a275983ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b8d6511530846cfb289df4374affa06",
            "placeholder": "​",
            "style": "IPY_MODEL_2941bba83cd24424ab920986f752ace4",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "ceab81b29ac54155b94ae0f8dec96e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbc2202c5bb6415da0a86e3a275983ef",
              "IPY_MODEL_182a0427955b4ac686018722bd5609e6",
              "IPY_MODEL_b425e1c736ad416b949bbbde5ba61c25"
            ],
            "layout": "IPY_MODEL_ba7407f3dafd4d30b32b6ff29b8de188"
          }
        },
        "cec011865f0042cfaf898222d29fb359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfb5ca21d3a34d7fa6da28ba8411ef2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98858911ab784c028d7d261116d384a9",
              "IPY_MODEL_ac2d20f9694a4079a1d2ee0edfbad543",
              "IPY_MODEL_e444f793a5ea47559bfa053a84e1eaec"
            ],
            "layout": "IPY_MODEL_a4a074620d6e443abe9bc9b38a303a5c"
          }
        },
        "d62b57bfec074e9a8a072599a327293e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f55476c81e17435d9ff1c2267d07c14c",
            "placeholder": "​",
            "style": "IPY_MODEL_800d1a1d62f044a3b14fbb935758af6b",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "d69504e6293c4512b942593c2c495111": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6a976fdeb64d578f9cc870c3117b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddca2744693b48b382bbfa8b3d022713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e444f793a5ea47559bfa053a84e1eaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ed98c3550048a9803439920134bd63",
            "placeholder": "​",
            "style": "IPY_MODEL_ac56aaa8dbdb400193f6f3dfb833572f",
            "value": " 792k/792k [00:00&lt;00:00, 2.28MB/s]"
          }
        },
        "f2c2a2d1898444f98110f81990a3d8ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55476c81e17435d9ff1c2267d07c14c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8cd81e8f43b4f36bc252e3041bef7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0259dce322bc4e879aab1a361d810348",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46f7f69ff2d64d1a87fcca0ac2926454",
            "value": 147
          }
        },
        "f8d78cc483ab4849aacd5db010d44d43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0bd2c4888334bc294380b70a6b4a189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e4b6c8a20004929a3d3dbbaf5a7c193",
              "IPY_MODEL_31c801ce79c346c19571cdbfcc443a96",
              "IPY_MODEL_c9976277e34a48b99e2fff7da7898291"
            ],
            "layout": "IPY_MODEL_85c017b13d3a406aaf718ca281b9bc64"
          }
        },
        "2e4b6c8a20004929a3d3dbbaf5a7c193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_684fd9dbc31f463d8c730e43d15c875a",
            "placeholder": "​",
            "style": "IPY_MODEL_549bca2cdd024b91a1de2e845d0d6ce5",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "31c801ce79c346c19571cdbfcc443a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3412c62c7d5426a85d627c8bba02585",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f2ca72b95ee4c01a0f062355ce30536",
            "value": 26
          }
        },
        "c9976277e34a48b99e2fff7da7898291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81cf26079a464140ae61e542a228ea59",
            "placeholder": "​",
            "style": "IPY_MODEL_d14bbbda1e7f42f38e371f577e0fc34e",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.24kB/s]"
          }
        },
        "85c017b13d3a406aaf718ca281b9bc64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684fd9dbc31f463d8c730e43d15c875a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "549bca2cdd024b91a1de2e845d0d6ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3412c62c7d5426a85d627c8bba02585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2ca72b95ee4c01a0f062355ce30536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81cf26079a464140ae61e542a228ea59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d14bbbda1e7f42f38e371f577e0fc34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6629a6f5b424371a24856e22994babf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6df19af955894d6f87d90ddefd54fc86",
              "IPY_MODEL_8fd7f0fa961f47e7b064de42c0328d7f",
              "IPY_MODEL_86cd541e2e7d41f2b0ebd5672ff8bbf8"
            ],
            "layout": "IPY_MODEL_1879049519a04da9b8c3634956acccd4"
          }
        },
        "6df19af955894d6f87d90ddefd54fc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cb3d6700b044cd28a1fb5938abc545d",
            "placeholder": "​",
            "style": "IPY_MODEL_8a3c1e4b0b39406f914e0548d340a20a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "8fd7f0fa961f47e7b064de42c0328d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd552abf25d7490b837726aee009156c",
            "max": 1802,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3db4aae5b6434b1ead1b1bb5e25beb19",
            "value": 1802
          }
        },
        "86cd541e2e7d41f2b0ebd5672ff8bbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca7b00db25fb41589b40892f1cd13488",
            "placeholder": "​",
            "style": "IPY_MODEL_6a053ed0072448efbc334a7ff3b3dbba",
            "value": " 1.80k/1.80k [00:00&lt;00:00, 96.3kB/s]"
          }
        },
        "1879049519a04da9b8c3634956acccd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cb3d6700b044cd28a1fb5938abc545d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a3c1e4b0b39406f914e0548d340a20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd552abf25d7490b837726aee009156c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db4aae5b6434b1ead1b1bb5e25beb19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca7b00db25fb41589b40892f1cd13488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a053ed0072448efbc334a7ff3b3dbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "379b869ed23c494fabdc5e4e0f4e5215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b6e0addcb1448d986abb3dc6f4a57fe",
              "IPY_MODEL_3b69edec7f4846a0ab7e8a130d4af7f7",
              "IPY_MODEL_ff4e5e17e5a948428e92074eeb7fe45d"
            ],
            "layout": "IPY_MODEL_72b8890f0557437687b67f523f8e9bbb"
          }
        },
        "2b6e0addcb1448d986abb3dc6f4a57fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90eaf82fb4a543a09cf484d09777d38a",
            "placeholder": "​",
            "style": "IPY_MODEL_804cd75ce8b444a3b6e1599e7883bf9b",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "3b69edec7f4846a0ab7e8a130d4af7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5cbe48035e4de3be35d0fda07814e4",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3f5466188144c4abb5632aec87b21b3",
            "value": 898822
          }
        },
        "ff4e5e17e5a948428e92074eeb7fe45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4de67449b96b4d779c8fc6021fe4192f",
            "placeholder": "​",
            "style": "IPY_MODEL_e0dc887f757545b2acd7a902dcbac3ea",
            "value": " 899k/899k [00:00&lt;00:00, 24.0MB/s]"
          }
        },
        "72b8890f0557437687b67f523f8e9bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90eaf82fb4a543a09cf484d09777d38a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804cd75ce8b444a3b6e1599e7883bf9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b5cbe48035e4de3be35d0fda07814e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3f5466188144c4abb5632aec87b21b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4de67449b96b4d779c8fc6021fe4192f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0dc887f757545b2acd7a902dcbac3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "370b5b0478a544eca7fe41206bc50371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e392593e0c304cd0b7734eed5d0bb5a9",
              "IPY_MODEL_ac5d544fe2194a6099129da7dce25c6d",
              "IPY_MODEL_8679eaf7e10a4267816f3b362734cea0"
            ],
            "layout": "IPY_MODEL_eda4ec307d694bdd9a09e33e4fee944d"
          }
        },
        "e392593e0c304cd0b7734eed5d0bb5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f24e49769b454c9437b4b30357121d",
            "placeholder": "​",
            "style": "IPY_MODEL_5580d400e2384f1c86d12bd662fab7ad",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "ac5d544fe2194a6099129da7dce25c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c45746f5c144474b8f5694d1dc8f4f2",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ab250e25b8841d8a3a8f3d98c808be9",
            "value": 456318
          }
        },
        "8679eaf7e10a4267816f3b362734cea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_611ddba88632420d979fbec974571901",
            "placeholder": "​",
            "style": "IPY_MODEL_37994059972d42d8bfd305f87885af19",
            "value": " 456k/456k [00:00&lt;00:00, 14.2MB/s]"
          }
        },
        "eda4ec307d694bdd9a09e33e4fee944d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f24e49769b454c9437b4b30357121d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5580d400e2384f1c86d12bd662fab7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c45746f5c144474b8f5694d1dc8f4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab250e25b8841d8a3a8f3d98c808be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "611ddba88632420d979fbec974571901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37994059972d42d8bfd305f87885af19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f1c8c585679453b924ff012925c29f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eabaddf91c3749138c5957d3585c6d5c",
              "IPY_MODEL_d2caad2b641e42748527d09a1ce676e6",
              "IPY_MODEL_e0f6e558bd744b68bf8860b1c85339f3"
            ],
            "layout": "IPY_MODEL_0857a775cde34a129a226373ee6182b8"
          }
        },
        "eabaddf91c3749138c5957d3585c6d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba010b3724f5463ea4ac2fc899ca00e0",
            "placeholder": "​",
            "style": "IPY_MODEL_ea56103285e24ba7bb96324d191bbad4",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "d2caad2b641e42748527d09a1ce676e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2a00ff23a484971a9b2a94272f561cb",
            "max": 1222317369,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e825c535d25949b98e25f21aeb644d8a",
            "value": 1222317369
          }
        },
        "e0f6e558bd744b68bf8860b1c85339f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f895f67e31e44f01a42d39b97c54266f",
            "placeholder": "​",
            "style": "IPY_MODEL_c6cce4906a43411c865d08bcf09dd5bb",
            "value": " 1.22G/1.22G [00:10&lt;00:00, 161MB/s]"
          }
        },
        "0857a775cde34a129a226373ee6182b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba010b3724f5463ea4ac2fc899ca00e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea56103285e24ba7bb96324d191bbad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2a00ff23a484971a9b2a94272f561cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e825c535d25949b98e25f21aeb644d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f895f67e31e44f01a42d39b97c54266f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6cce4906a43411c865d08bcf09dd5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7010775c6e464460a52b80290f84db88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9155f311d38422e86053dbcff2447a0",
              "IPY_MODEL_b1c1f32a2292453384ca299053e55aeb",
              "IPY_MODEL_8e5199f7e7b9483fa87d78530157e7c8"
            ],
            "layout": "IPY_MODEL_ff03fe04fccd4aefa5afa23099cce2f8"
          }
        },
        "a9155f311d38422e86053dbcff2447a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d200e47dbb4f7595dae0cdab74a8ec",
            "placeholder": "​",
            "style": "IPY_MODEL_99d40d0efcf5480d866c76297626fb60",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "b1c1f32a2292453384ca299053e55aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7ca75f1f2f745bcac3be306c8828072",
            "max": 512568261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60da870bb2514a29a7e5759c4fdcee9d",
            "value": 512568261
          }
        },
        "8e5199f7e7b9483fa87d78530157e7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77669810f0424671b5e1f8466f7e55d6",
            "placeholder": "​",
            "style": "IPY_MODEL_04b37887e7144b1888fc81bf8f41e2fb",
            "value": " 513M/513M [00:02&lt;00:00, 264MB/s]"
          }
        },
        "ff03fe04fccd4aefa5afa23099cce2f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d200e47dbb4f7595dae0cdab74a8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d40d0efcf5480d866c76297626fb60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7ca75f1f2f745bcac3be306c8828072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60da870bb2514a29a7e5759c4fdcee9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77669810f0424671b5e1f8466f7e55d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b37887e7144b1888fc81bf8f41e2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}